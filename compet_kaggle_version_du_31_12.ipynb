{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 90248,
          "databundleVersionId": 10480827,
          "sourceType": "competition"
        },
        {
          "sourceId": 214728,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 183064,
          "modelId": 205264
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Confection de résumés automatiques d'articles scientifiques par un modèle de langue pré-entraîné : étude et comparaison des performances de deux modèles.\n",
        "\n",
        "**Auteur.e.s :** Sophie perrin, Emma, El Zube, Marius, Sylvano, pour le cours *Representation learning for NLP* @ Master 2 MALIA et MIASHS.\n",
        "\n",
        "**Equipe :** les léopards"
      ],
      "metadata": {
        "id": "Jm3aCEp_w2w2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Préparation de l'environnement\n",
        "\n",
        "1. Se connecter ou se créer un compte sur https://huggingface.co/\n",
        "2. Se créer un nouveau token d'accès : https://huggingface.co/settings/tokens\n",
        "3. Enregistrer ce token comme un secret nommé `HF_TOKEN` dans Google Colab (icone \"clef\" dans le bandeau vertical)\n",
        "4. Exécuter le code ci-dessous\n",
        "\n",
        "Note importante pour la vitesse de calcul : pour activer l'accélération GPU dans votre notebook Kaggle :\n",
        "\n",
        "    Ouvrez le menu « Settings » : Dans votre notebook Kaggle, cliquez sur le menu « Accelerator » en haut de l'écran, et choisissez un GPU.\n",
        "\n",
        "    Dans ce même menu, vérifiez qu'il n'est pas écrit \"turn off internet\" - sinon cliquer dessus pour rétablir l'accès au reste d'internet depuis kaggle. Si vous n'avez ni \"turn off internet\" ni \"turn on internet\" d'écrit, alors il faut ajouter votre téléphone et votre photo pour certifier votre identité pour le compte, avant de pouvoir accéder au reste d'internet depuis kaggle (nécessaire pour charger les modèles de huggingface et même les packages de python...!).\n",
        "\n"
      ],
      "metadata": {
        "id": "oiCaaZ8YC8hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "id": "3pp0itMoj78l",
        "outputId": "6fc6780e-9cd4-447f-c06d-f7f325e10549",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:45.093500Z",
          "iopub.execute_input": "2024-12-30T22:31:45.093786Z",
          "iopub.status.idle": "2024-12-30T22:31:45.556256Z",
          "shell.execute_reply.started": "2024-12-30T22:31:45.093762Z",
          "shell.execute_reply": "2024-12-30T22:31:45.555289Z"
        },
        "colab": {
          "referenced_widgets": [
            "84b989c3aebb43bea0c77a629951c9ff"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84b989c3aebb43bea0c77a629951c9ff"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "m_2_maliash_resume_darticles_scientifiques_path = kagglehub.competition_download('m-2-maliash-resume-darticles-scientifiques')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "z-S3zGw4BfUX",
        "outputId": "b91c7e68-5d81-41a5-e693-63e126680a97",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:45.557603Z",
          "iopub.execute_input": "2024-12-30T22:31:45.557918Z",
          "iopub.status.idle": "2024-12-30T22:31:46.296147Z",
          "shell.execute_reply.started": "2024-12-30T22:31:45.557886Z",
          "shell.execute_reply": "2024-12-30T22:31:46.295192Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Data source import complete.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Pour créer le \"HF_TOKEN\" dans Kaggle, aller dans \"Add-ons\" (dans les menus de ce notebook, juste à gauche de \"Help\").\n",
        "#Une fois là, aller dans \"secrets\", puis ça marche à peu près comme dans colab : il faut nommer la variable (HF_TOKEN) et\n",
        "#y copier sa valeur.\n",
        "\n",
        "\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "user_secrets = UserSecretsClient()\n",
        "secret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:46.297916Z",
          "iopub.execute_input": "2024-12-30T22:31:46.298167Z",
          "iopub.status.idle": "2024-12-30T22:31:46.460736Z",
          "shell.execute_reply.started": "2024-12-30T22:31:46.298144Z",
          "shell.execute_reply": "2024-12-30T22:31:46.459840Z"
        },
        "id": "AzT78O1Subpo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation des données d'entraînement pour leur utilisation par le modèle"
      ],
      "metadata": {
        "id": "hoSW39T9djGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Données du fichier OBS"
      ],
      "metadata": {
        "id": "Jacj2VHTubpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On crée un dictionnaire qui apparie les articles de l'ensemble d'entraînement (\"fine tuning\" puisque le modèle est déjà pré-entraîné) et leurs résumés par leur identifiant commun."
      ],
      "metadata": {
        "id": "iSOUl2N1dtAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A noter que quelques résumés n'ont pas d'article qui leur correspond !"
      ],
      "metadata": {
        "id": "ySTyiFhjd0i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemins dans Kaggle des dossiers contenant les fichiers\n",
        "dossier_abstracts = \"/kaggle/input/m-2-maliash-resume-darticles-scientifiques/train/OBS/abstracts_OBS/\"\n",
        "dossier_articles = \"/kaggle/input/m-2-maliash-resume-darticles-scientifiques/train/OBS/articles_OBS/\"\n",
        "\n",
        "\n",
        "# Liste des fichiers dans chaque dossier\n",
        "fichiers_abstracts = [f for f in os.listdir(dossier_abstracts) if f.startswith(\"abstract-\")]\n",
        "fichiers_articles = [f for f in os.listdir(dossier_articles) if f.startswith(\"article-\")]\n",
        "\n",
        "# Dictionnaires pour stocker les fichiers par identifiant\n",
        "abstracts = {}\n",
        "articles = {}\n",
        "\n",
        "# Remplir les dictionnaires avec les fichiers en fonction des identifiants\n",
        "for fichier in fichiers_abstracts:\n",
        "    # Extraire l'identifiant du fichier abstract\n",
        "    identifiant = fichier.split(\"-\")[1].split(\".\")[0]\n",
        "     #fichier.split(\"-\") : La méthode split(\"-\") divise le nom du fichier\n",
        "    #en une liste de sous-chaînes en utilisant le caractère \"-\" comme séparateur.\n",
        "    #Par exemple, si le fichier est \"abstract-123.txt\", fichier.split(\"-\") renverra la liste [\"abstract\", \"123.txt\"].\n",
        "    #fichier.split(\"-\")[1] : En prenant l'élément d'indice 1 de cette liste (c'est-à-dire \"123.txt\"), on obtient la partie du nom du fichier après le préfixe \"abstract-\".\n",
        "    #split(\".\")[0] : Ensuite, on divise cette chaîne \"123.txt\" avec split(\".\"), ce qui donne [\"123\", \"txt\"].\n",
        "    #On prend le premier élément de la liste (c'est-à-dire \"123\") qui est l'identifiant unique de l'abstract.\n",
        "    abstracts[identifiant] = fichier\n",
        "    #Cette ligne ajoute une entrée dans le dictionnaire abstracts, où la clé est : identifiant (par exemple \"123\")\n",
        "    #et la valeur est le nom du fichier : fichier (par exemple \"abstract-123.txt\").\n",
        "\n",
        "for fichier in fichiers_articles:\n",
        "    # Extraire l'identifiant du fichier article\n",
        "    identifiant = fichier.split(\"-\")[1].split(\".\")[0]\n",
        "    articles[identifiant] = fichier\n",
        "\n",
        "# Dictionnaire pour stocker les appariements\n",
        "appariements = {}\n",
        "\n",
        "# Liste des abstracts et articles non-appariés\n",
        "non_apparies_abstracts = []\n",
        "non_apparies_articles = []\n",
        "\n",
        "# Appariement des fichiers abstracts et articles par identifiant\n",
        "for identifiant in abstracts:\n",
        "    if identifiant in articles:\n",
        "        # Ajouter l'appariement au dictionnaire\n",
        "        appariements[identifiant] = {\n",
        "            \"abstract\": abstracts[identifiant],\n",
        "            \"article\": articles[identifiant]\n",
        "        }\n",
        "    else:\n",
        "        # Ajouter à la liste des abstracts non appariés\n",
        "        non_apparies_abstracts.append(abstracts[identifiant])\n",
        "\n",
        "# Vérifier les articles non-appariés\n",
        "for identifiant in articles:\n",
        "    if identifiant not in abstracts:\n",
        "        # Ajouter à la liste des articles non appariés\n",
        "        non_apparies_articles.append(articles[identifiant])\n",
        "\n",
        "# Affichage des appariements\n",
        "\"\"\"\n",
        "print(\"Appariements :\")\n",
        "for identifiant, fichiers in appariements.items():\n",
        "    print(f\"Identifiant {identifiant}:\")\n",
        "    print(f\"  Abstract: {fichiers['abstract']}\")\n",
        "    print(f\"  Article: {fichiers['article']}\")\n",
        "\"\"\"\n",
        "# Affichage des abstracts non-appariés\n",
        "print(\"\\nAbstracts non-appariés :\")\n",
        "for abstract in non_apparies_abstracts:\n",
        "    print(abstract)\n",
        "\n",
        "# Affichage des articles non-appariés\n",
        "print(\"\\nArticles non-appariés :\")\n",
        "for article in non_apparies_articles:\n",
        "    print(article)"
      ],
      "metadata": {
        "id": "_5wciJ57jnhk",
        "outputId": "b9096f10-f7a2-4209-fc66-42350f644ec5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:46.462144Z",
          "iopub.execute_input": "2024-12-30T22:31:46.462465Z",
          "iopub.status.idle": "2024-12-30T22:31:46.504614Z",
          "shell.execute_reply.started": "2024-12-30T22:31:46.462430Z",
          "shell.execute_reply": "2024-12-30T22:31:46.503782Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nAbstracts non-appariés :\nabstract-36404343.txt\nabstract-38022520.txt\nabstract-37614109.txt\nabstract-36944082.txt\nabstract-32017677.txt\nabstract-36944050.txt\nabstract-36891751.txt\nabstract-35081022.txt\nabstract-32091358.txt\nabstract-31625835.txt\nabstract-36066965.txt\nabstract-36519326.txt\nabstract-36525381.txt\nabstract-36314570.txt\nabstract-37833688.txt\nabstract-27423055.txt\nabstract-37796016.txt\nabstract-37026745.txt\nabstract-36068298.txt\nabstract-35324507.txt\nabstract-37726286.txt\nabstract-37102598.txt\nabstract-36951168.txt\nabstract-24279685.txt\nabstract-36944043.txt\nabstract-32946618.txt\nabstract-36372692.txt\n\nArticles non-appariés :\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "On retravaille un peu la forme de ce dictionnaire pour pouvoir le convertir au format \"dataset\" de Hugging face, nécessaire pour pouvoir entraîner le modèle choisi dessus.\n"
      ],
      "metadata": {
        "id": "7axwPxrAd7Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets #le \"-U\" demande l'installation de la toute dernière version du package\n",
        "from datasets import Dataset #importe la classe Dataset de la bibliothèque datasets de Hugging Face.\n",
        "#Cette classe est utilisée pour manipuler des ensembles de données dans un format qui peut être utilisé pour l'entraînement de modèles issus d'Hugging Face.\n",
        "\n",
        "# Limiter le nombre de threads de JAX à 1 (pour éviter les problèmes dans kaggle)\n",
        "os.environ[\"JAX_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "#Notre dictionnaire appariements n'est pas tout à fait sous la bonne forme pour être transformé en dataset de Hugging Face :\n",
        "#on le remanie donc pour qu'il ait cette bonne forme.\n",
        "\n",
        "# Initialisation des listes vides\n",
        "identifiants = []\n",
        "articles = []\n",
        "abstracts = []\n",
        "\n",
        "# Remplir les listes avec les données extraites du dictionnaire appariements\n",
        "for identifiant, values in appariements.items():\n",
        "    identifiants.append(identifiant)         # Ajout de l'identifiant\n",
        "    articles.append(values[\"article\"])      # Ajout de l'article\n",
        "    abstracts.append(values[\"abstract\"])    # Ajout de l'abstract\n",
        "\n",
        "# Créer un dictionnaire avec les listes\n",
        "data = {\n",
        "    \"identifiant\": identifiants,\n",
        "    \"article\": articles,\n",
        "    \"abstract\": abstracts\n",
        "}\n",
        "\n",
        "# Créer le Dataset en convertissant notre nouveau dictionnaire via l'instruction Dataset.from_dict() de Dataset\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "wJ-fvqMz7ahj",
        "outputId": "5cc78080-3b1a-48ba-9db2-27872f4ec33c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:46.505515Z",
          "iopub.execute_input": "2024-12-30T22:31:46.505812Z",
          "iopub.status.idle": "2024-12-30T22:31:52.627391Z",
          "shell.execute_reply.started": "2024-12-30T22:31:46.505783Z",
          "shell.execute_reply": "2024-12-30T22:31:52.626396Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDataset({\n    features: ['identifiant', 'article', 'abstract'],\n    num_rows: 402\n})\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## le fichier à utiliser pour l'entraînement du modèle sur les articles de type OBS sera donc \"dataset\""
      ],
      "metadata": {
        "id": "SdR5_I5UubqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Données RCT"
      ],
      "metadata": {
        "id": "q_PR_9ZMubqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On procède de même pour les données des articles de type \"RCT\""
      ],
      "metadata": {
        "id": "mPSvN9u3ubqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Chemins dans Kaggle des dossiers contenant les fichiers\n",
        "dossier_abstracts = \"/kaggle/input/m-2-maliash-resume-darticles-scientifiques/train/RCT/abstracts_RCT/\"\n",
        "dossier_articles = \"/kaggle/input/m-2-maliash-resume-darticles-scientifiques/train/RCT/articles_RCT/\"\n",
        "\n",
        "\n",
        "# Liste des fichiers dans chaque dossier\n",
        "fichiers_abstracts = [f for f in os.listdir(dossier_abstracts) if f.startswith(\"abstract-\")]\n",
        "fichiers_articles = [f for f in os.listdir(dossier_articles) if f.startswith(\"article-\")]\n",
        "\n",
        "# Dictionnaires pour stocker les fichiers par identifiant\n",
        "abstracts = {}\n",
        "articles = {}\n",
        "\n",
        "# Remplir les dictionnaires avec les fichiers en fonction des identifiants\n",
        "for fichier in fichiers_abstracts:\n",
        "    # Extraire l'identifiant du fichier abstract\n",
        "    identifiant = fichier.split(\"-\")[1].split(\".\")[0]\n",
        "     #fichier.split(\"-\") : La méthode split(\"-\") divise le nom du fichier\n",
        "    #en une liste de sous-chaînes en utilisant le caractère \"-\" comme séparateur.\n",
        "    #Par exemple, si le fichier est \"abstract-123.txt\", fichier.split(\"-\") renverra la liste [\"abstract\", \"123.txt\"].\n",
        "    #fichier.split(\"-\")[1] : En prenant l'élément d'indice 1 de cette liste (c'est-à-dire \"123.txt\"), on obtient la partie du nom du fichier après le préfixe \"abstract-\".\n",
        "    #split(\".\")[0] : Ensuite, on divise cette chaîne \"123.txt\" avec split(\".\"), ce qui donne [\"123\", \"txt\"].\n",
        "    #On prend le premier élément de la liste (c'est-à-dire \"123\") qui est l'identifiant unique de l'abstract.\n",
        "    abstracts[identifiant] = fichier\n",
        "    #Cette ligne ajoute une entrée dans le dictionnaire abstracts, où la clé est : identifiant (par exemple \"123\")\n",
        "    #et la valeur est le nom du fichier : fichier (par exemple \"abstract-123.txt\").\n",
        "\n",
        "for fichier in fichiers_articles:\n",
        "    # Extraire l'identifiant du fichier article\n",
        "    identifiant = fichier.split(\"-\")[1].split(\".\")[0]\n",
        "    articles[identifiant] = fichier\n",
        "\n",
        "# Dictionnaire pour stocker les appariements\n",
        "appariements_RCT = {}\n",
        "\n",
        "# Liste des abstracts et articles non-appariés\n",
        "non_apparies_abstracts_RCT = []\n",
        "non_apparies_articles_RCT = []\n",
        "\n",
        "# Appariement des fichiers abstracts et articles par identifiant\n",
        "for identifiant in abstracts:\n",
        "    if identifiant in articles:\n",
        "        # Ajouter l'appariement au dictionnaire\n",
        "        appariements_RCT[identifiant] = {\n",
        "            \"abstract\": abstracts[identifiant],\n",
        "            \"article\": articles[identifiant]\n",
        "        }\n",
        "    else:\n",
        "        # Ajouter à la liste des abstracts non appariés\n",
        "        non_apparies_abstracts_RCT.append(abstracts[identifiant])\n",
        "\n",
        "# Vérifier les articles non-appariés\n",
        "for identifiant in articles:\n",
        "    if identifiant not in abstracts:\n",
        "        # Ajouter à la liste des articles non appariés\n",
        "        non_apparies_articles_RCT.append(articles[identifiant])\n",
        "\n",
        "# Affichage des appariements\n",
        "\"\"\"\n",
        "print(\"Appariements_RCT :\")\n",
        "for identifiant, fichiers in appariements_RCT.items():\n",
        "    print(f\"Identifiant {identifiant}:\")\n",
        "    print(f\"  Abstract: {fichiers['abstract']}\")\n",
        "    print(f\"  Article: {fichiers['article']}\")\n",
        "\"\"\"\n",
        "# Affichage des abstracts non-appariés\n",
        "print(\"\\nAbstracts non-appariés :\")\n",
        "for abstract in non_apparies_abstracts_RCT:\n",
        "    print(abstract)\n",
        "\n",
        "# Affichage des articles non-appariés\n",
        "print(\"\\nArticles non-appariés :\")\n",
        "for article in non_apparies_articles_RCT:\n",
        "    print(article)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:52.628490Z",
          "iopub.execute_input": "2024-12-30T22:31:52.628827Z",
          "iopub.status.idle": "2024-12-30T22:31:52.691396Z",
          "shell.execute_reply.started": "2024-12-30T22:31:52.628802Z",
          "shell.execute_reply": "2024-12-30T22:31:52.690382Z"
        },
        "id": "QHadKTDDubqW",
        "outputId": "f9e58a0e-4b97-4aa9-a062-8a5c39fa1fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nAbstracts non-appariés :\nabstract-24164420.txt\nabstract-36082590.txt\nabstract-36872899.txt\nabstract-37030393.txt\nabstract-37722926.txt\nabstract-36451616.txt\nabstract-36094045.txt\nabstract-37157134.txt\nabstract-36877135.txt\nabstract-36289532.txt\nabstract-24266855.txt\nabstract-37565064.txt\nabstract-37614106.txt\nabstract-33153517.txt\nabstract-37562034.txt\nabstract-37690911.txt\nabstract-31431084.txt\nabstract-33984185.txt\nabstract-24268098.txt\nabstract-36542086.txt\nabstract-36053287.txt\nabstract-32418064.txt\nabstract-37302021.txt\nabstract-37463508.txt\nabstract-31507265.txt\nabstract-33674243.txt\nabstract-36271420.txt\nabstract-36129998.txt\nabstract-36525381.txt\nabstract-29172800.txt\nabstract-37392348.txt\nabstract-32868525.txt\nabstract-28961557.txt\nabstract-37551774.txt\nabstract-35986699.txt\nabstract-27421672.txt\nabstract-34713539.txt\nabstract-36503413.txt\nabstract-35751625.txt\nabstract-35982483.txt\nabstract-36309392.txt\nabstract-35974668.txt\nabstract-30394151.txt\nabstract-37217019.txt\nabstract-32869931.txt\nabstract-37639901.txt\nabstract-37379733.txt\nabstract-34724172.txt\nabstract-34984792.txt\nabstract-37605171.txt\nabstract-36321647.txt\n\nArticles non-appariés :\narticle- 35751625.txt\narticle- 32868525.txt\narticle- 35982483.txt\narticle- 26959498.txt\narticle- 30982467.txt\narticle- 24747297.txt\narticle- 32482570.txt\narticle-37728775.txt\narticle- 31402562.txt\narticle- 36068298.txt\narticle- 36084331.txt\narticle- 31431084.txt\narticle- 36129998.txt\narticle- 25003802.txt\narticle- 24859440.txt\narticle- 37030393.txt\narticle- 27671861 .txt\narticle- 31076287.txt\narticle- 33984185.txt\narticle- 32162274.txt\narticle- 24401143.txt\narticle- 24368640.txt\narticle- 24593269.txt\narticle- 36059000.txt\narticle- 24708472.txt\narticle- 34713539.txt\narticle- 24533998.txt\narticle-25474530.txt\narticle- 34984792.txt\narticle- 31507265.txt\narticle- 27421971.txt\narticle- 24671488.txt\narticle- 24700992.txt\narticle- 36525381.txt\narticle- 36542086.txt\narticle- 25616223.txt\narticle-35671123 .txt\narticle- 36891751.txt\narticle- 25398189.txt\narticle- 37302021.txt\narticle- 36503413.txt\narticle- 30394151.txt\narticle- 24045440.txt\narticle- 36878722.txt\narticle- 29172800.txt\narticle- 31436896.txt\narticle- 29212509.txt\narticle-32988385 .txt\narticle- 24983707.txt\narticle- 24379118.txt\narticle- 24447332.txt\narticle- 25123116.txt\narticle- 24341382.txt\narticle- 25038794.txt\narticle- 29041941.txt\narticle- 24666558.txt\narticle- 24322060.txt\narticle-35713933 .txt\narticle-36631450.txt\narticle-36095045.txt\narticle-36469329.txt\narticle- 26229189.txt\narticle- 37562034.txt\narticle- 30997149.txt\narticle- 25588847.txt\narticle- 36872899.txt\narticle- 36066965.txt\narticle- 37551774.txt\narticle- 24859367.txt\narticle- 30793375.txt\narticle- 28671938.txt\narticle- 31625835.txt\narticle- 30997153.txt\narticle-37766477.txt\narticle- 36289532.txt\narticle- 25123172.txt\narticle- 25514459.txt\narticle- 29490675.txt\narticle- 36271420.txt\narticle- 26993316.txt\narticle- 27423055.txt\narticle- 36082590.txt\narticle- 33674243.txt\narticle- 24354476 .txt\narticle- 24618231 .txt\narticle- 35974668.txt\narticle- 24708443 .txt\narticle- 32017677.txt\narticle- 25083614.txt\narticle- 29208026.txt\narticle- 26468632.txt\narticle- 26666236.txt\narticle- 37463508.txt\narticle- 34138698.txt\narticle- 31969108.txt\narticle- 24108196 .txt\narticle- 32091358.txt\narticle- 27645694.txt\narticle- 30713721.txt\narticle- 23732262.txt\narticle- 24747090.txt\narticle- 24999963.txt\narticle- 24568148.txt\narticle- 37379733.txt\narticle- 24630150.txt\narticle- 24506815.txt\narticle- 29464843.txt\narticle- 36321647.txt\narticle- 32869931.txt\narticle- 37392348.txt\narticle- 24825528.txt\narticle- 36669352.txt\narticle- 37565064.txt\narticle- 28961557.txt\narticle- 24296904.txt\narticle- 36631450.txt\narticle- 30713722.txt\narticle- 24597619.txt\narticle-32562807.txt\narticle- 34724172.txt\narticle- 30008335.txt\narticle- 24597650.txt\narticle- 36451616.txt\narticle- 30008335.txt\narticle- 30886732 .txt\narticle- 36053287.txt\narticle- 30846389.txt\narticle- 37217019.txt\narticle- 37052929.txt\narticle- 34184312.txt\narticle- 37605171.txt\narticle- 24378686.txt\narticle- 35986699.txt\narticle- 24781374.txt\narticle- 37690911.txt\narticle- 24521771.txt\narticle- 33153517.txt\narticle- 37157134.txt\narticle- 24333515.txt\narticle- 37722926.txt\narticle-36446771.txt\narticle- 24263324.txt\narticle-38012031.txt\narticle- 27600280.txt\narticle- 24519331.txt\narticle- 36309392.txt\narticle- 25110374.txt\narticle- 24036678.txt\narticle- 24700991.txt\narticle- 32316911.txt\narticle- 36877135.txt\narticle- 24518774.txt\narticle- 24248149.txt\narticle- 24448650.txt\narticle- 25193416.txt\narticle-37614109.txt\narticle- 30554670.txt\narticle- 25936892.txt\narticle- 32164522.txt\narticle- 24279685.txt\narticle- 25474530.txt\narticle- 29258549.txt\narticle- 24184336.txt\narticle- 24637869.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets #le \"-U\" demande l'installation de la toute dernière version du package\n",
        "from datasets import Dataset #importe la classe Dataset de la bibliothèque datasets de Hugging Face.\n",
        "#Cette classe est utilisée pour manipuler des ensembles de données dans un format qui peut être utilisé pour l'entraînement de modèles issus d'Hugging Face.\n",
        "\n",
        "# Limiter le nombre de threads de JAX à 1 (pour éviter les problèmes dans kaggle)\n",
        "os.environ[\"JAX_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "#Notre dictionnaire appariements_RCT n'est pas tout à fait sous la bonne forme pour être transformé en dataset de Hugging Face :\n",
        "#on le remanie donc pour qu'il ait cette bonne forme.\n",
        "\n",
        "# Initialisation des listes vides\n",
        "identifiants = []\n",
        "articles = []\n",
        "abstracts = []\n",
        "\n",
        "# Remplir les listes avec les données extraites du dictionnaire appariements\n",
        "for identifiant, values in appariements_RCT.items():\n",
        "    identifiants.append(identifiant)         # Ajout de l'identifiant\n",
        "    articles.append(values[\"article\"])      # Ajout de l'article\n",
        "    abstracts.append(values[\"abstract\"])    # Ajout de l'abstract\n",
        "\n",
        "# Créer un dictionnaire avec les listes\n",
        "data = {\n",
        "    \"identifiant\": identifiants,\n",
        "    \"article\": articles,\n",
        "    \"abstract\": abstracts\n",
        "}\n",
        "\n",
        "# Créer le Dataset en convertissant notre nouveau dictionnaire via l'instruction Dataset.from_dict() de Dataset\n",
        "dataset_RCT = Dataset.from_dict(data)\n",
        "\n",
        "#print(dataset_RCT)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:52.692252Z",
          "iopub.execute_input": "2024-12-30T22:31:52.692542Z",
          "iopub.status.idle": "2024-12-30T22:31:56.234047Z",
          "shell.execute_reply.started": "2024-12-30T22:31:52.692507Z",
          "shell.execute_reply": "2024-12-30T22:31:56.232991Z"
        },
        "id": "m3GkYLr0ubqX",
        "outputId": "5295e065-7091-4ce7-dc40-e3caea26c3e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Le fichier à utiliser pour l'entrainement sur les données RCT sera donc \"dataset_RCT\""
      ],
      "metadata": {
        "id": "reNZiLfhubqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essai du modèle bigbird-pegasus-large-arxiv"
      ],
      "metadata": {
        "id": "8Ro7elpOubqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce modèle a pour singularité, par rapport à des modèles de type BERT, d'utiliser une version modifiée de l'architecture Transformer : il a un mécanisme d'attention sparse (attention réduite) par blocs. Concrètement, cela signifie qu'au lieu de calculer l'attention entre toutes les positions du texte, il divise la séquence (le texte) en blocs et applique l'attention uniquement au sein de ces blocs, ainsi qu'entre certains blocs (par exemple les blocs voisins ou un échantillonnage aléatoire de blocs).\n",
        "\n",
        "Cela permet d'être économe en temps de calcul : avec un modèle de type BERT, ce dernier croissait en $O(N^2)$, où $N$ représente la taille du texte (ou document). Avec le mécanisme d'attention sparse par blocs, on tombe à des temps de calcul en $O(N.log(N))$ ou en $O(N)$.\n",
        "\n",
        "Pour nos articles scientifiques, qui sont des documents longs, ce type de modèles, avec attention sparse par blocs, peut donc être particulièrement pertinent."
      ],
      "metadata": {
        "id": "fUiZk0D9q-c1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On convertit maintenant le texte des articles et des résumés (ici ceux de type \"OBS\") en séquences de tokens pour le modèle bigbird-pegasus-large-arxiv."
      ],
      "metadata": {
        "id": "eDcpedpneMHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Fonction pour préparer les données (tokenisation) pour un modèle chargé depuis huggingface\n",
        "def tokenize_function(examples):\n",
        "    # Tokeniser les articles et les résumés\n",
        "    inputs = tokenizer(examples['article'], truncation=True, padding=\"max_length\", max_length=1024) #données en entrée\n",
        "    #examples['article'] : C'est la donnée brute (l'article) fournie à la fonction sous forme de texte.\n",
        "    #Cette donnée vient d'un Dataset ou d'une DataLoader et est passée sous forme de liste de textes (articles).\n",
        "    #tokenizer(examples['article']) : Cette ligne utilise le tokenizer pour convertir le texte brut des articles en une séquence de tokens.\n",
        "    #Le tokenizer transforme le texte en un format compréhensible par le modèle (i.e., des IDs de tokens).\n",
        "\n",
        "    #truncation=True : Si le texte est plus long que la longueur maximale définie, il sera tronqué pour correspondre à cette longueur maximale.\n",
        "\n",
        "    #padding=\"max_length\" : Cela permet de remplir (padd) le texte pour qu'il atteigne la longueur maximale spécifiée.\n",
        "    #Si un article est plus court que la longueur maximale, des tokens de remplissage seront ajoutés.\n",
        "\n",
        "    #max_length=1024 : La longueur maximale des séquences d'entrée est fixée à 1024 tokens. Si un article est plus long que cela, il sera tronqué à 1024 tokens.\n",
        "\n",
        "    targets = tokenizer(examples['abstract'], truncation=True, padding=\"max_length\", max_length=256)#données cible de l'entrainement du modèle\n",
        "\n",
        "    # Retourner les inputs et targets sous la forme de dictionnaires\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    #inputs[\"labels\"] : Dans un modèle de génération de texte comme BigBirdPegasus, les labels sont les séquences que le modèle doit prédire\n",
        "    #(les résumés dans ce cas). En d'autres termes, le modèle apprend à prédire les tokens du résumé à partir des tokens de l'article.\n",
        "    #targets[\"input_ids\"] : input_ids est la représentation des tokens du résumé (les IDs numériques des tokens). Ces tokens sont utilisés comme labels lors de l'entraînement,\n",
        "    #c'est-à-dire que le modèle essaiera de prédire ces input_ids lorsqu'il verra les tokens des articles.\n",
        "    #Cette ligne ajoute donc les input_ids des résumés dans la clé \"labels\" des données d'entrée, qui est utilisée pendant l'entraînement pour calculer la perte\n",
        "    #entre les prédictions du modèle et les résumés réels.\n",
        "    return inputs\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "41fMtp6-pHgH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:56.235227Z",
          "iopub.execute_input": "2024-12-30T22:31:56.235573Z",
          "iopub.status.idle": "2024-12-30T22:31:56.241697Z",
          "shell.execute_reply.started": "2024-12-30T22:31:56.235542Z",
          "shell.execute_reply": "2024-12-30T22:31:56.240793Z"
        },
        "outputId": "d5489776-d571-4ff6-98ad-3f491ba1f226"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n# Fonction pour préparer les données (tokenisation) pour un modèle chargé depuis huggingface\\ndef tokenize_function(examples):\\n    # Tokeniser les articles et les résumés\\n    inputs = tokenizer(examples[\\'article\\'], truncation=True, padding=\"max_length\", max_length=1024) #données en entrée\\n    #examples[\\'article\\'] : C\\'est la donnée brute (l\\'article) fournie à la fonction sous forme de texte.\\n    #Cette donnée vient d\\'un Dataset ou d\\'une DataLoader et est passée sous forme de liste de textes (articles).\\n    #tokenizer(examples[\\'article\\']) : Cette ligne utilise le tokenizer pour convertir le texte brut des articles en une séquence de tokens.\\n    #Le tokenizer transforme le texte en un format compréhensible par le modèle (i.e., des IDs de tokens).\\n\\n    #truncation=True : Si le texte est plus long que la longueur maximale définie, il sera tronqué pour correspondre à cette longueur maximale.\\n\\n    #padding=\"max_length\" : Cela permet de remplir (padd) le texte pour qu\\'il atteigne la longueur maximale spécifiée.\\n    #Si un article est plus court que la longueur maximale, des tokens de remplissage seront ajoutés.\\n\\n    #max_length=1024 : La longueur maximale des séquences d\\'entrée est fixée à 1024 tokens. Si un article est plus long que cela, il sera tronqué à 1024 tokens.\\n\\n    targets = tokenizer(examples[\\'abstract\\'], truncation=True, padding=\"max_length\", max_length=256)#données cible de l\\'entrainement du modèle\\n\\n    # Retourner les inputs et targets sous la forme de dictionnaires\\n    inputs[\"labels\"] = targets[\"input_ids\"]\\n    #inputs[\"labels\"] : Dans un modèle de génération de texte comme BigBirdPegasus, les labels sont les séquences que le modèle doit prédire\\n    #(les résumés dans ce cas). En d\\'autres termes, le modèle apprend à prédire les tokens du résumé à partir des tokens de l\\'article.\\n    #targets[\"input_ids\"] : input_ids est la représentation des tokens du résumé (les IDs numériques des tokens). Ces tokens sont utilisés comme labels lors de l\\'entraînement,\\n    #c\\'est-à-dire que le modèle essaiera de prédire ces input_ids lorsqu\\'il verra les tokens des articles.\\n    #Cette ligne ajoute donc les input_ids des résumés dans la clé \"labels\" des données d\\'entrée, qui est utilisée pendant l\\'entraînement pour calculer la perte\\n    #entre les prédictions du modèle et les résumés réels.\\n    return inputs\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement du modèle bigbird-pegasus-large-arxiv\n",
        "\n"
      ],
      "metadata": {
        "id": "TxbTu-oNDOC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer # Import TrainingArguments and Trainer\n",
        "\n",
        "#Instancier le tokenizer pour le modèle pegasus\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/bigbird-pegasus-large-arxiv/\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
        "#chargement du modèle :\n",
        "# by default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64/par défaut l'encoder-attention est \"block sparse\"\n",
        "#avec num_random_blocks=3 et block_size=64\n",
        "#model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"/kaggle/input/bigbird-pegasus-large-arxiv/\",\n",
        "model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\",\n",
        "                                                               return_dict=True,\n",
        "                                                               torch_dtype=torch.float16,\n",
        "                                                               device_map=\"auto\")\n",
        "\"\"\"\n",
        "######################Options pour modifier la taille et le nombre des blocs d'attention :\n",
        "# decoder attention type can't be changed & will be \"original_full\"\n",
        "# you can change `attention_type` (encoder only) to full attention like this:\n",
        "##model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", attention_type=\"original_full\")\n",
        "\n",
        "# you can change `block_size` & `num_random_blocks` like this:\n",
        "##model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", block_size=16, num_random_blocks=2)\n",
        "######################\n",
        "\n"
      ],
      "metadata": {
        "id": "j1WNnycYXvQM",
        "outputId": "89d58390-0900-4b3b-f348-a00bb02a5e7c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:56.244553Z",
          "iopub.execute_input": "2024-12-30T22:31:56.244812Z",
          "iopub.status.idle": "2024-12-30T22:31:56.263509Z",
          "shell.execute_reply.started": "2024-12-30T22:31:56.244791Z",
          "shell.execute_reply": "2024-12-30T22:31:56.262562Z"
        }
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nfrom transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\\nimport torch\\nfrom transformers import TrainingArguments, Trainer # Import TrainingArguments and Trainer\\n\\n#Instancier le tokenizer pour le modèle pegasus\\n#tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/bigbird-pegasus-large-arxiv/\")\\ntokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\\n#chargement du modèle :\\n# by default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64/par défaut l\\'encoder-attention est \"block sparse\"\\n#avec num_random_blocks=3 et block_size=64\\n#model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"/kaggle/input/bigbird-pegasus-large-arxiv/\",\\nmodel = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\",\\n                                                               return_dict=True,\\n                                                               torch_dtype=torch.float16,\\n                                                               device_map=\"auto\")\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrainement du modèle bigbird-pegasus-large-arxiv et conclusions sur ce modèle pour notre compétition kaggle"
      ],
      "metadata": {
        "id": "BRVkDGaHubqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On paramètre l'entraînement du modèle.\n",
        "\n",
        "Problème : même en modifiant les paramètres de training_args comme ci-dessous, pour tenter de consommer moins de mémoire, l'entraînement de ce modèle fait planter la session kaggle car il consomme trop de mémoire - y compris en utilisant les GPU 100, ceux qui comportent le plus de mémoire sur kaggle.\n",
        "\n",
        "Nous allons donc tester un autre modèle, composé par l'assemblage de bart-large-cnn et longformer-base-4096, et bart-large-cnn seul (simplement fine-tuné sur nos données d'entraînement)."
      ],
      "metadata": {
        "id": "s9i3nuomeifY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Appliquer la tokenisation\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Définir les arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bigbird_pegasus_finetuned\",  # Répertoire de sortie pour enregistrer les résultats\n",
        "    evaluation_strategy=\"epoch\",  # Évaluer après chaque époque\n",
        "    learning_rate=2e-5,  # Taux d'apprentissage\n",
        "    per_device_train_batch_size=1, #2 je réduis pour éviter de planter kaggle,  # Taille du batch pour l'entraînement\n",
        "    per_device_eval_batch_size=1, #2 idem,   # Taille du batch pour l'évaluation\n",
        "    gradient_accumulation_steps=8,  # Accumuler les gradients sur 8 batches avant la mise à jour (réduit l'utilisation de la mémoire, toujours pour éviter de planter kaggle)\n",
        "                                    #cela \"simule\" une taille de batch plus grande que ce qu'elle n'est en réalité ici\n",
        "    fp16=False,  # Activer l'entraînement en 16-bit - toujours pour éviter de planter kaggle\n",
        "    num_train_epochs=3,  # Nombre d'époques d'entraînement\n",
        "    dataloader_num_workers=4,  # Utiliser 4 processus pour charger les données en parallèle\n",
        "    gradient_checkpointing=True,  # Activer gradient checkpointing\n",
        "    save_steps=500,  # Sauvegarder moins souvent\n",
        "    weight_decay=0.01,  # L2 regularization\n",
        "    save_total_limit=2,  # Limite du nombre de sauvegardes du modèle\n",
        "    logging_dir=\"./logs\",  # Répertoire pour les logs\n",
        "    logging_steps=100,  # Fréquence des logs\n",
        "    report_to=\"tensorboard\",  # Optionnel : Utiliser TensorBoard pour la visualisation des métriques\n",
        ")\n",
        "\n",
        "# Créer un objet Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,  # Le modèle à fine-tuner\n",
        "    args=training_args,  # Les arguments d'entraînement\n",
        "    train_dataset=train_dataset,  # Jeu d'entraînement\n",
        "    eval_dataset=val_dataset,  # Jeu de validation\n",
        "    compute_metrics=compute_metrics,  # Fonction pour calculer les métriques - elle nous permettra d'utiliser le score \"ROUGE\"\n",
        ")\n",
        "\n",
        "# Lancer l'entraînement\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "# Sauvegarder le modèle fine-tuné\n",
        "trainer.save_model(\"./bigbird_pegasus_finetuned\")\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9_UU-nmJqoiQ",
        "outputId": "08af7291-0207-4cbf-b546-3431e5c94376",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:56.265505Z",
          "iopub.execute_input": "2024-12-30T22:31:56.265739Z",
          "iopub.status.idle": "2024-12-30T22:31:56.282975Z",
          "shell.execute_reply.started": "2024-12-30T22:31:56.265719Z",
          "shell.execute_reply": "2024-12-30T22:31:56.282172Z"
        }
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n# Appliquer la tokenisation\\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\\n\\n# Définir les arguments d\\'entraînement\\ntraining_args = TrainingArguments(\\n    output_dir=\"./bigbird_pegasus_finetuned\",  # Répertoire de sortie pour enregistrer les résultats\\n    evaluation_strategy=\"epoch\",  # Évaluer après chaque époque\\n    learning_rate=2e-5,  # Taux d\\'apprentissage\\n    per_device_train_batch_size=1, #2 je réduis pour éviter de planter kaggle,  # Taille du batch pour l\\'entraînement\\n    per_device_eval_batch_size=1, #2 idem,   # Taille du batch pour l\\'évaluation\\n    gradient_accumulation_steps=8,  # Accumuler les gradients sur 8 batches avant la mise à jour (réduit l\\'utilisation de la mémoire, toujours pour éviter de planter kaggle)\\n                                    #cela \"simule\" une taille de batch plus grande que ce qu\\'elle n\\'est en réalité ici\\n    fp16=False,  # Activer l\\'entraînement en 16-bit - toujours pour éviter de planter kaggle\\n    num_train_epochs=3,  # Nombre d\\'époques d\\'entraînement\\n    dataloader_num_workers=4,  # Utiliser 4 processus pour charger les données en parallèle\\n    gradient_checkpointing=True,  # Activer gradient checkpointing\\n    save_steps=500,  # Sauvegarder moins souvent\\n    weight_decay=0.01,  # L2 regularization\\n    save_total_limit=2,  # Limite du nombre de sauvegardes du modèle\\n    logging_dir=\"./logs\",  # Répertoire pour les logs\\n    logging_steps=100,  # Fréquence des logs\\n    report_to=\"tensorboard\",  # Optionnel : Utiliser TensorBoard pour la visualisation des métriques\\n)\\n\\n# Créer un objet Trainer\\ntrainer = Trainer(\\n    model=model,  # Le modèle à fine-tuner\\n    args=training_args,  # Les arguments d\\'entraînement\\n    train_dataset=train_dataset,  # Jeu d\\'entraînement\\n    eval_dataset=val_dataset,  # Jeu de validation\\n    compute_metrics=compute_metrics,  # Fonction pour calculer les métriques - elle nous permettra d\\'utiliser le score \"ROUGE\"\\n)\\n\\n# Lancer l\\'entraînement\\ntrainer.train()\\n\\n\\n# Sauvegarder le modèle fine-tuné\\ntrainer.save_model(\"./bigbird_pegasus_finetuned\")\\n\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Essai du modèle Bart-large-cnn seul"
      ],
      "metadata": {
        "id": "O3nIaRYvubqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BART est un modèle de transformer encodeur-décodeur (seq2seq : \"sequence to séquence\") avec un encodeur bidirectionnel (similaire à BERT) et un décodeur autoregressif (similaire à GPT).\n",
        "Il est pré-entraîné en masquant des parties du texte et en apprenant à prédire ces parties - comme si on lui demandait de débruiter un texte bruité.\n",
        "Il utilise une attention dense classique pour un transformer, où chaque token de l'entrée prend en compte tous les autres tokens de la séquence. Cela le handicape donc pour nos articles longs (comme tous les modèles à attention dense classique)."
      ],
      "metadata": {
        "id": "_ogvtW3usO7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compléter ici avec les conclusions qui nous ont fait ne pas retenir ce modèle seul non plus..."
      ],
      "metadata": {
        "id": "AR0IyRXuubqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confection d'un modèle composé à partir de longformer et bart"
      ],
      "metadata": {
        "id": "qSzMxKkWubqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement du modèle  allenai/longformer-base-4096\n",
        "\n"
      ],
      "metadata": {
        "id": "wBJW2co1ubqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle bigbird-pegasus-large-arivx demande trop de mémoire pour notre plateforme de compétition kaggle.\n",
        "\n",
        "Nous devons donc nous orienter vers un modèle de compromis, néanmoins adapté au traitement d'articles scientifiques longs.\n",
        "Il nous faut donc chercher dans la famille des modèles à attention \"sparse\", les seuls vraiment adaptés pour ces textes longs.\n",
        "\n",
        "allenai/longformer-large-4096 partage avec bigbird ce mécanisme d'attention sparse : tout comme lui, il utilise une fenêtre d'attention \"glissante\". Tout comme lui, il y ajoute une attention à plus longue portée sur les tokens importants, ce qui lui permet d'interagir avec tous les autres tokens de la séquence pour capturer des relations à long terme. Mais en revanche, contrairement à lui, il n'a pas de mécanisme d'attention aléatoire qui se surajoute à ces deux couches d'attention, et qui lui permet de mieux capter des relations globales...mais consomme de la mémoire vive, lors de son entraînement (fine tuning) notamment.\n",
        "\n",
        "En revanche, il n'est pas un générateur de texte : il nous faut donc l'associer à un modèle de type GPT ou autre qui permet quant à lui la génération. Ce, dans le but de bonifier les performances du modèle générateur par les bonnes performances de longformer sur les textes longs.\n",
        "On l'associe avec le modèle générateur bart-large-cnn, association qu'on crée \"à la main\" via la confection d'une classe spécifique.\n",
        "\n",
        "Comme le modèle ainsi créé reste trop volumineux, on y remplace finalement allenai/longformer-large-4096 par une version plus légère : allenai/longformer-base-4096.\n",
        "\n"
      ],
      "metadata": {
        "id": "b9rFHGjOubqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer # Import TrainingArguments and Trainer\n",
        "\n",
        "# Instancier le tokenizer pour le modèle Longformer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "\n",
        "# Chargement du modèle Longformer\n",
        "# Longformer n'a pas de modèle direct pour la génération de texte comme BigBird-PEGASUS, donc ici, nous utilisons un modèle Longformer pour classification de séquences.\n",
        "# Si vous voulez adapter Longformer pour la génération de texte, vous devrez peut-être fine-tuner un modèle approprié sur une tâche comme la génération.\n",
        "\n",
        "model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\",\n",
        "                                                           return_dict=True,\n",
        "                                                           torch_dtype=torch.float16,\n",
        "                                                           device_map=\"auto\")\n",
        "\n",
        "# Si vous avez besoin de fine-tuner ce modèle sur une tâche spécifique (comme le résumé), vous devrez remplacer le modèle par un modèle adapté à la génération."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:31:56.283884Z",
          "iopub.execute_input": "2024-12-30T22:31:56.284153Z",
          "iopub.status.idle": "2024-12-30T22:32:15.744776Z",
          "shell.execute_reply.started": "2024-12-30T22:31:56.284132Z",
          "shell.execute_reply": "2024-12-30T22:32:15.744044Z"
        },
        "colab": {
          "referenced_widgets": [
            "059fc9bf2f7a4753a2e7066aa6cc1dc9",
            "3b30b35d32124610b1bccf97880e67c7",
            "d718735bb2d64409ac668f1b31f2fd2b",
            "863f7a062b4040f691b7d9826f4d7e7f",
            "a1ab3b9163a3480c829a9f80fcbd0d0a"
          ]
        },
        "id": "qr-OCEgbubqy",
        "outputId": "1c611db7-405f-438b-b3a6-3b44f36e3afe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "059fc9bf2f7a4753a2e7066aa6cc1dc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b30b35d32124610b1bccf97880e67c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d718735bb2d64409ac668f1b31f2fd2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "863f7a062b4040f691b7d9826f4d7e7f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1ab3b9163a3480c829a9f80fcbd0d0a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création du nouveau modèle \"cousu main\" à partir de BART et LONGFORMER"
      ],
      "metadata": {
        "id": "EPBYVYguubq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On est obligé de faire un peu de \"cuisine\" pour associer les 2 modèles en un seul : par exemple, les sorties de longformer n'ont pas la même taille que les entrées de bart. Il nous faut donc insérer dans la classe une \"couche de projection\".\n",
        "Il faut également dupliquer leurs poids, pour éviter les (mauvais...) mélanges entre eux par la suite.\n",
        "\n",
        "On ne peut pas utiliser la tokenisation de l'un des deux modèles non plus : il nous faut en créer une, tout aussi hybride que notre modèle \"fait main\" à partir de la couture de ces deux modèles issus de hugging face."
      ],
      "metadata": {
        "id": "8TgLbWdZubq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerTokenizer, BartTokenizer, BartForConditionalGeneration, LongformerModel, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Charger le tokenizer et le modèle Longformer pour l'encodage\n",
        "longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "longformer_model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "\n",
        "# Charger le tokenizer et le modèle BART-CNN pour la génération\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "bart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Tokenisation des entrées et des sorties\n",
        "def tokenize_function(examples):\n",
        "    # Tokeniser les articles avec Longformer\n",
        "    model_inputs = longformer_tokenizer(\n",
        "        examples[\"article\"],\n",
        "        #max_length=4096, #trop long pour le GPU de kaggle...\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Assurer le padding\n",
        "        return_tensors=\"pt\"  # Retourner des tensors PyTorch\n",
        "    )\n",
        "\n",
        "    # Tokeniser les résumés (labels) avec BART tokenizer\n",
        "    labels = bart_tokenizer(\n",
        "        #examples[\"highlights\"],\n",
        "        examples[\"abstract\"],\n",
        "        #max_length=200,\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Assurer le padding\n",
        "        return_tensors=\"pt\"  # Retourner des tensors PyTorch\n",
        "    )\n",
        "\n",
        "    # Ajouter les labels au dictionnaire de sortie\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Définir un modèle combiné qui utilise Longformer comme encodeur et BART pour la génération\n",
        "class LongformerBart(nn.Module):\n",
        "    def __init__(self, longformer_model, bart_model):\n",
        "        super(LongformerBart, self).__init__()\n",
        "        self.longformer = longformer_model\n",
        "        self.bart = bart_model\n",
        "\n",
        " # Ajouter une couche linéaire pour ajuster la dimension des sorties de Longformer\n",
        "        self.longformer_projection = nn.Linear(768, 1024)  # Projeter de 768 à 1024\n",
        "\n",
        " # Dupliquer les poids partagés de BART et Longformer\n",
        "        with torch.no_grad():\n",
        "            # Dupliquer les poids partagés de BART\n",
        "            bart_model.model.shared = torch.nn.Embedding.from_pretrained(bart_model.model.shared.weight.clone())\n",
        "            bart_model.model.encoder.embed_tokens = torch.nn.Embedding.from_pretrained(bart_model.model.encoder.embed_tokens.weight.clone())\n",
        "            bart_model.model.decoder.embed_tokens = torch.nn.Embedding.from_pretrained(bart_model.model.decoder.embed_tokens.weight.clone())\n",
        "\n",
        "            # Dupliquer les poids partagés de Longformer\n",
        "            longformer_model.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(longformer_model.embeddings.word_embeddings.weight.clone())\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_input_ids=None, labels=None):\n",
        "        # Encoder la séquence avec Longformer\n",
        "        encoder_outputs = self.longformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        encoder_hidden_states = encoder_outputs.last_hidden_state\n",
        "\n",
        "  # Appliquer la projection pour ajuster la dimension\n",
        "        encoder_hidden_states = self.longformer_projection(encoder_hidden_states)\n",
        "\n",
        "        # Passer les représentations encodées à BART pour la génération\n",
        "        decoder_outputs = self.bart(\n",
        "            input_ids=decoder_input_ids,\n",
        "            labels=labels,\n",
        "            encoder_outputs=encoder_hidden_states\n",
        "        )\n",
        "\n",
        "        return decoder_outputs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:32:15.745576Z",
          "iopub.execute_input": "2024-12-30T22:32:15.746147Z",
          "iopub.status.idle": "2024-12-30T22:32:27.460112Z",
          "shell.execute_reply.started": "2024-12-30T22:32:15.746122Z",
          "shell.execute_reply": "2024-12-30T22:32:27.459182Z"
        },
        "colab": {
          "referenced_widgets": [
            "e18d384311184b96a2f6760defbe626e",
            "2244a4553b414c0381d8b6afcd6f12ce",
            "7a309b8fe2f049e98219ca4b682a9bb5",
            "f5deccdb59f44fdab4307b651f339cf4",
            "36855e16e1364223a8bffb7472915c74",
            "87f384d9b4594558acf4f6998df6c25c"
          ]
        },
        "id": "PW_ZtoAuubq8",
        "outputId": "fc1f9231-ebab-4c36-9b0e-ea9c86b1dac0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e18d384311184b96a2f6760defbe626e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2244a4553b414c0381d8b6afcd6f12ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a309b8fe2f049e98219ca4b682a9bb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5deccdb59f44fdab4307b651f339cf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36855e16e1364223a8bffb7472915c74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87f384d9b4594558acf4f6998df6c25c"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement de ce modèle sur les données OBS, puis sauvegarde de ce modèle ainsi fine-tuné\n"
      ],
      "metadata": {
        "id": "7uRwU-76ubrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliquer la tokenisation\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Diviser l'ensemble de données en train et validation\n",
        "dataset_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "\n",
        "# Extraire les ensembles d'entraînement et de validation\n",
        "train_dataset = dataset_split['train']\n",
        "val_dataset = dataset_split['test']\n",
        "\n",
        "\n",
        "\n",
        "# Initialiser le modèle combiné\n",
        "model = LongformerBart(longformer_model, bart_model)\n",
        "\n",
        "# Définir les arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./longformer_bart_finetuned\",  # Répertoire de sortie pour enregistrer les résultats\n",
        "    evaluation_strategy=\"epoch\",  # Évaluer après chaque époque\n",
        "    learning_rate=2e-5,  # Taux d'apprentissage\n",
        "    per_device_train_batch_size=2,  # Taille du batch pour l'entraînement\n",
        "    per_device_eval_batch_size=2,   # Taille du batch pour l'évaluation\n",
        "    num_train_epochs=3,  # Nombre d'époques d'entraînement\n",
        "    save_steps=500,  # Sauvegarder moins souvent\n",
        "    weight_decay=0.01,  # L2 regularization\n",
        "    logging_dir=\"./logs\",  # Répertoire pour les logs\n",
        "    logging_steps=10,  # Fréquence des logs\n",
        "    report_to=\"tensorboard\",  # Optionnel : Utiliser TensorBoard pour la visualisation des métriques\n",
        ")\n",
        "\n",
        "\n",
        "# Créer un objet Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,  # Le modèle combiné Longformer+BART\n",
        "    args=training_args,  # Les arguments d'entraînement\n",
        "    train_dataset=train_dataset,  # Jeu d'entraînement\n",
        "    eval_dataset=val_dataset,  # Jeu de validation\n",
        "    tokenizer=longformer_tokenizer,  # Tokenizer pour le pré-traitement des données\n",
        ")\n",
        "\n",
        "# Lancer l'entraînement\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:32:27.461065Z",
          "iopub.execute_input": "2024-12-30T22:32:27.461401Z",
          "iopub.status.idle": "2024-12-30T22:42:31.324020Z",
          "shell.execute_reply.started": "2024-12-30T22:32:27.461364Z",
          "shell.execute_reply": "2024-12-30T22:42:31.323249Z"
        },
        "colab": {
          "referenced_widgets": [
            "152e62026b82487eb29c7346135254a3"
          ]
        },
        "id": "IfHgL8yeubrD",
        "outputId": "a6a66b2d-aaff-4334-cfb1-9d672449470c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/402 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "152e62026b82487eb29c7346135254a3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='483' max='483' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [483/483 09:56, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.061900</td>\n      <td>1.215846</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.044400</td>\n      <td>6.686377</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.042600</td>\n      <td>2.663265</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=483, training_loss=0.5426618188434507, metrics={'train_runtime': 598.6016, 'train_samples_per_second': 1.609, 'train_steps_per_second': 0.807, 'total_flos': 0.0, 'train_loss': 0.5426618188434507, 'epoch': 3.0})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Dupliquer les poids partagés pour éviter la duplication de mémoire\n",
        "# Cela doit être fait après l'entraînement et avant la sauvegarde\n",
        "\n",
        "import safetensors.torch as st\n",
        "\n",
        "# Pour Longformer - dupliquer les embeddings\n",
        "with torch.no_grad():  # Empêche la modification des gradients\n",
        "    new_word_embeddings = model.longformer.embeddings.word_embeddings.weight.clone()\n",
        "    model.longformer.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(new_word_embeddings)\n",
        "\n",
        "# Pour BART - dupliquer les embeddings de l'encodeur et du décodeur\n",
        "with torch.no_grad():  # Empêche la modification des gradients\n",
        "    new_shared_weight = model.bart.model.shared.weight.clone()\n",
        "    model.bart.model.shared = torch.nn.Embedding.from_pretrained(new_shared_weight)\n",
        "\n",
        "    new_encoder_embed = model.bart.model.encoder.embed_tokens.weight.clone()\n",
        "    model.bart.model.encoder.embed_tokens = torch.nn.Embedding.from_pretrained(new_encoder_embed)\n",
        "\n",
        "    new_decoder_embed = model.bart.model.decoder.embed_tokens.weight.clone()\n",
        "    model.bart.model.decoder.embed_tokens = torch.nn.Embedding.from_pretrained(new_decoder_embed)\n",
        "\n",
        "# Sauvegarder les poids dans un fichier classique\n",
        "torch.save(model.state_dict(), 'longformer_bart_finetuned/model_weights.pth')\n",
        "\n",
        "# Charger manuellement avec safetensors (si vous avez configuré safetensors)\n",
        "import safetensors.torch as st\n",
        "\n",
        "# Sauvegarder avec safetensors après avoir dupliqué les poids\n",
        "st.save_file(model.state_dict(), 'longformer_bart_finetuned/model_weights.safetensors')\n",
        "\n",
        "import json\n",
        "\n",
        "# Définir la configuration\n",
        "config = {\n",
        "    \"architectures\": [\"LongformerForSequenceClassification\"],\n",
        "    \"hidden_size\": 1024,\n",
        "    \"num_attention_heads\": 16,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"vocab_size\": 50264,\n",
        "    \"max_position_embeddings\": 4098,\n",
        "    \"embedding_size\": 1024,\n",
        "    \"layer_norm_eps\": 1e-5,\n",
        "    \"pad_token_id\": 1,\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_affine\": True,\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 4098,\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"attention_dropout\": 0.1,\n",
        "    \"longformer_projection\": {\n",
        "        \"in_features\": 768,\n",
        "        \"out_features\": 1024\n",
        "    }\n",
        "}\n",
        "\n",
        "# Sauvegarder le fichier config.json\n",
        "#config_path = '/kaggle/working/config.json'\n",
        "with open(\"longformer_bart_finetuned/config.json\", 'w') as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "print(\"Le fichier config.json a été sauvegardé \")\n",
        "\n",
        "# Sauvegarder le modèle fine-tuné\n",
        "trainer.save_model(\"./longformer_bart_finetuned\")\n",
        "\"\"\"\n",
        "# Sauvegarde du modèle\n",
        "torch.save(longformer_bart_model.state_dict(), \"longformer_bart_finetuned.pth\")\n",
        "\n",
        "# Sauvegarde de la configuration\n",
        "longformer_bart_model.config.to_json_file(\"longformer_bart_config.json\")\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:42:31.324897Z",
          "iopub.execute_input": "2024-12-30T22:42:31.325221Z",
          "iopub.status.idle": "2024-12-30T22:42:52.636695Z",
          "shell.execute_reply.started": "2024-12-30T22:42:31.325177Z",
          "shell.execute_reply": "2024-12-30T22:42:52.635782Z"
        },
        "id": "1jyuirn5ubrF",
        "outputId": "c8f99517-ce15-4302-f689-66d0e508b9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Le fichier config.json a été sauvegardé \n",
          "output_type": "stream"
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n# Sauvegarde du modèle\\ntorch.save(longformer_bart_model.state_dict(), \"longformer_bart_finetuned.pth\")\\n\\n# Sauvegarde de la configuration\\nlongformer_bart_model.config.to_json_file(\"longformer_bart_config.json\")\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# Chemin du dossier à supprimer\n",
        "directory_to_delete = \"/kaggle/working/longformer_bart_finetuned/checkpoint-483\"\n",
        "# Vérifier si le dossier existe\n",
        "if os.path.exists(directory_to_delete):\n",
        "    # Supprimer le dossier et tout son contenu\n",
        "    shutil.rmtree(directory_to_delete)\n",
        "    print(f\"Le dossier '{directory_to_delete}' a été supprimé avec succès.\")\n",
        "else:\n",
        "    print(f\"Le dossier '{directory_to_delete}' n'existe pas.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:42:52.637526Z",
          "iopub.execute_input": "2024-12-30T22:42:52.637753Z",
          "iopub.status.idle": "2024-12-30T22:43:13.534881Z",
          "shell.execute_reply.started": "2024-12-30T22:42:52.637732Z",
          "shell.execute_reply": "2024-12-30T22:43:13.534111Z"
        },
        "id": "MfAlB1KdubrG",
        "outputId": "27d15907-31c4-4a2f-dcd0-7603aa2e977b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Le dossier '/kaggle/working/longformer_bart_finetuned/checkpoint-483' a été supprimé avec succès.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "On zipe le dossier du modèle ainsi créé et entraîné, pour pouvoir le sauvegarder et le réutiliser ensuite sur notre ensemble de test :\n"
      ],
      "metadata": {
        "id": "YkJL6mBWubrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "print(os.listdir(\"./\"))\n",
        "\n",
        "shutil.make_archive('/kaggle/working/longformer_bart_finetuned', 'zip', './longformer_bart_finetuned')\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "id": "M7rlXM1XubrI",
        "outputId": "78356f65-4962-4f06-9c71-86d5896ed167"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['.virtual_documents', 'logs', 'longformer_bart_finetuned', 'submission.csv']\n",
          "output_type": "stream"
        },
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/kaggle/working/longformer_bart_finetuned.zip'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement de ce modèle sur les données RCT, puis sauvegarde de ce modèle fine-tuné"
      ],
      "metadata": {
        "id": "b-G7qN2gubrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Appliquer la tokenisation\n",
        "tokenized_datasets = dataset_RCT.map(tokenize_function, batched=True)\n",
        "\n",
        "# Diviser l'ensemble de données en train et validation\n",
        "dataset_split = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "\n",
        "# Extraire les ensembles d'entraînement et de validation\n",
        "train_dataset = dataset_split['train']\n",
        "val_dataset = dataset_split['test']\n",
        "\n",
        "\n",
        "\n",
        "# Initialiser le modèle combiné\n",
        "model = LongformerBart(longformer_model, bart_model)\n",
        "\n",
        "# Définir les arguments d'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./longformer_bart_finetuned_rct\",  # Répertoire de sortie pour enregistrer les résultats\n",
        "    evaluation_strategy=\"epoch\",  # Évaluer après chaque époque\n",
        "    learning_rate=2e-5,  # Taux d'apprentissage\n",
        "    per_device_train_batch_size=2,  # Taille du batch pour l'entraînement\n",
        "    per_device_eval_batch_size=2,   # Taille du batch pour l'évaluation\n",
        "    num_train_epochs=3,  # Nombre d'époques d'entraînement\n",
        "    save_steps=500,  # Sauvegarder moins souvent\n",
        "    weight_decay=0.01,  # L2 regularization\n",
        "    logging_dir=\"./logs\",  # Répertoire pour les logs\n",
        "    logging_steps=10,  # Fréquence des logs\n",
        "    report_to=\"tensorboard\",  # Optionnel : Utiliser TensorBoard pour la visualisation des métriques\n",
        ")\n",
        "\n",
        "\n",
        "# Créer un objet Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,  # Le modèle combiné Longformer+BART\n",
        "    args=training_args,  # Les arguments d'entraînement\n",
        "    train_dataset=train_dataset,  # Jeu d'entraînement\n",
        "    eval_dataset=val_dataset,  # Jeu de validation\n",
        "    tokenizer=longformer_tokenizer,  # Tokenizer pour le pré-traitement des données\n",
        ")\n",
        "\n",
        "# Lancer l'entraînement\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:13.541763Z",
          "iopub.execute_input": "2024-12-30T22:43:13.542009Z",
          "iopub.status.idle": "2024-12-30T22:43:13.557210Z",
          "shell.execute_reply.started": "2024-12-30T22:43:13.541978Z",
          "shell.execute_reply": "2024-12-30T22:43:13.556514Z"
        },
        "id": "udLkHc3nubrJ",
        "outputId": "ec6a030d-0ab5-4642-b29d-144ed4c32bc5"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n# Appliquer la tokenisation\\ntokenized_datasets = dataset_RCT.map(tokenize_function, batched=True)\\n\\n# Diviser l\\'ensemble de données en train et validation\\ndataset_split = tokenized_datasets.train_test_split(test_size=0.2)\\n\\n# Extraire les ensembles d\\'entraînement et de validation\\ntrain_dataset = dataset_split[\\'train\\']\\nval_dataset = dataset_split[\\'test\\']\\n\\n        \\n\\n# Initialiser le modèle combiné\\nmodel = LongformerBart(longformer_model, bart_model)\\n\\n# Définir les arguments d\\'entraînement\\ntraining_args = TrainingArguments(\\n    output_dir=\"./longformer_bart_finetuned_rct\",  # Répertoire de sortie pour enregistrer les résultats\\n    evaluation_strategy=\"epoch\",  # Évaluer après chaque époque\\n    learning_rate=2e-5,  # Taux d\\'apprentissage\\n    per_device_train_batch_size=2,  # Taille du batch pour l\\'entraînement\\n    per_device_eval_batch_size=2,   # Taille du batch pour l\\'évaluation\\n    num_train_epochs=3,  # Nombre d\\'époques d\\'entraînement\\n    save_steps=500,  # Sauvegarder moins souvent\\n    weight_decay=0.01,  # L2 regularization\\n    logging_dir=\"./logs\",  # Répertoire pour les logs\\n    logging_steps=10,  # Fréquence des logs\\n    report_to=\"tensorboard\",  # Optionnel : Utiliser TensorBoard pour la visualisation des métriques\\n)\\n\\n\\n# Créer un objet Trainer\\ntrainer = Trainer(\\n    model=model,  # Le modèle combiné Longformer+BART\\n    args=training_args,  # Les arguments d\\'entraînement\\n    train_dataset=train_dataset,  # Jeu d\\'entraînement\\n    eval_dataset=val_dataset,  # Jeu de validation\\n    tokenizer=longformer_tokenizer,  # Tokenizer pour le pré-traitement des données\\n)\\n\\n# Lancer l\\'entraînement\\ntrainer.train()\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Dupliquer les poids partagés pour éviter la duplication de mémoire\n",
        "# Cela doit être fait après l'entraînement et avant la sauvegarde\n",
        "\n",
        "import safetensors.torch as st\n",
        "\n",
        "# Pour Longformer - dupliquer les embeddings\n",
        "with torch.no_grad():  # Empêche la modification des gradients\n",
        "    new_word_embeddings = model.longformer.embeddings.word_embeddings.weight.clone()\n",
        "    model.longformer.embeddings.word_embeddings = torch.nn.Embedding.from_pretrained(new_word_embeddings)\n",
        "\n",
        "# Pour BART - dupliquer les embeddings de l'encodeur et du décodeur\n",
        "with torch.no_grad():  # Empêche la modification des gradients\n",
        "    new_shared_weight = model.bart.model.shared.weight.clone()\n",
        "    model.bart.model.shared = torch.nn.Embedding.from_pretrained(new_shared_weight)\n",
        "\n",
        "    new_encoder_embed = model.bart.model.encoder.embed_tokens.weight.clone()\n",
        "    model.bart.model.encoder.embed_tokens = torch.nn.Embedding.from_pretrained(new_encoder_embed)\n",
        "\n",
        "    new_decoder_embed = model.bart.model.decoder.embed_tokens.weight.clone()\n",
        "    model.bart.model.decoder.embed_tokens = torch.nn.Embedding.from_pretrained(new_decoder_embed)\n",
        "\n",
        "# Sauvegarder les poids dans un fichier classique\n",
        "torch.save(model.state_dict(), 'longformer_bart_finetuned_rct/model_weights.pth')\n",
        "\n",
        "# Sauvegarder avec safetensors après avoir dupliqué les poids\n",
        "st.save_file(model.state_dict(), 'longformer_bart_finetuned_rct/model_weights.safetensors')\n",
        "\n",
        "\n",
        "from transformers import PretrainedConfig\n",
        "\n",
        "import json\n",
        "\n",
        "# Définir la configuration\n",
        "config = {\n",
        "    \"architectures\": [\"LongformerForSequenceClassification\"],\n",
        "    \"hidden_size\": 1024,\n",
        "    \"num_attention_heads\": 16,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"vocab_size\": 50264,\n",
        "    \"max_position_embeddings\": 4098,\n",
        "    \"embedding_size\": 1024,\n",
        "    \"layer_norm_eps\": 1e-5,\n",
        "    \"pad_token_id\": 1,\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_affine\": True,\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 4098,\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"attention_dropout\": 0.1,\n",
        "    \"longformer_projection\": {\n",
        "        \"in_features\": 768,\n",
        "        \"out_features\": 1024\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Sauvegarder le fichier config.json\n",
        "with open(\"longformer_bart_finetuned_rct/config.json\", 'w') as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "print(\"Le fichier config.json a été sauvegardé \")\n",
        "\n",
        "\n",
        "# Sauvegarder le modèle fine-tuné\n",
        "trainer.save_model(\"./longformer_bart_finetuned_rct\")\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "# Sauvegarde du modèle\n",
        "torch.save(longformer_bart_model.state_dict(), \"longformer_bart_finetuned.pth\")\n",
        "\n",
        "# Sauvegarde de la configuration\n",
        "longformer_bart_model.config.to_json_file(\"longformer_bart_config.json\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:13.558126Z",
          "iopub.execute_input": "2024-12-30T22:43:13.558464Z",
          "iopub.status.idle": "2024-12-30T22:43:13.577474Z",
          "shell.execute_reply.started": "2024-12-30T22:43:13.558432Z",
          "shell.execute_reply": "2024-12-30T22:43:13.576640Z"
        },
        "id": "WanN17PMubrM",
        "outputId": "da398a58-a14d-4aff-d67f-50051c96af0b"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n# Sauvegarde du modèle\\ntorch.save(longformer_bart_model.state_dict(), \"longformer_bart_finetuned.pth\")\\n\\n# Sauvegarde de la configuration\\nlongformer_bart_model.config.to_json_file(\"longformer_bart_config.json\")\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# Chemin du dossier à supprimer\n",
        "directory_to_delete = \"/kaggle/working/longformer_bart_finetuned_rct/checkpoint-393\"\n",
        "# Vérifier si le dossier existe\n",
        "if os.path.exists(directory_to_delete):\n",
        "    # Supprimer le dossier et tout son contenu\n",
        "    shutil.rmtree(directory_to_delete)\n",
        "    print(f\"Le dossier '{directory_to_delete}' a été supprimé avec succès.\")\n",
        "else:\n",
        "    print(f\"Le dossier '{directory_to_delete}' n'existe pas.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:13.578229Z",
          "iopub.execute_input": "2024-12-30T22:43:13.578481Z",
          "iopub.status.idle": "2024-12-30T22:43:13.597519Z",
          "shell.execute_reply.started": "2024-12-30T22:43:13.578462Z",
          "shell.execute_reply": "2024-12-30T22:43:13.596689Z"
        },
        "id": "XL_AXyHFubrP",
        "outputId": "1e700185-c1c0-49fa-cd97-aecbf763cf3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Le dossier '/kaggle/working/longformer_bart_finetuned_rct/checkpoint-393' n'existe pas.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "On zipe le dossier du modèle ainsi créé et entraîné, pour pouvoir le sauvegarder et le réutiliser ensuite sur notre ensemble de test :"
      ],
      "metadata": {
        "id": "t0tP9cVmubrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import shutil\n",
        "\n",
        "print(os.listdir(\"./\"))\n",
        "\n",
        "shutil.make_archive('/kaggle/working/longformer_bart_finetuned_rct', 'zip', './longformer_bart_finetuned_rct')\n",
        "\"\"\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:13.598256Z",
          "iopub.execute_input": "2024-12-30T22:43:13.598586Z",
          "iopub.status.idle": "2024-12-30T22:43:13.613521Z",
          "shell.execute_reply.started": "2024-12-30T22:43:13.598551Z",
          "shell.execute_reply": "2024-12-30T22:43:13.612797Z"
        },
        "id": "aiYwYdPiubrU",
        "outputId": "480dc8eb-a369-402b-9df9-c6b04ec22873"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nimport shutil\\n\\nprint(os.listdir(\"./\"))\\n\\nshutil.make_archive(\\'/kaggle/working/longformer_bart_finetuned_rct\\', \\'zip\\', \\'./longformer_bart_finetuned_rct\\')\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement de notre modèle fine-tuné sur les données \"OBS\" et constitué à partir des deux modèles bart et longformer, pour pouvoir l'utiliser pour l'ensemble de test et soumettre nos résumés pour la compétition"
      ],
      "metadata": {
        "id": "ukhaminRubrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Charger le modèle fine tuné afin de l'utiliser\n",
        "import torch\n",
        "from transformers import LongformerModel, BartForConditionalGeneration, LongformerConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Définir la classe LongformerBart\n",
        "class LongformerBart(nn.Module):\n",
        "    def __init__(self, longformer_model, bart_model):\n",
        "        super(LongformerBart, self).__init__()\n",
        "        self.longformer = longformer_model\n",
        "        self.bart = bart_model\n",
        "        self.longformer_projection = nn.Linear(768, 1024)  # Projeter de 768 à 1024\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_input_ids=None, labels=None):\n",
        "        encoder_outputs = self.longformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        encoder_hidden_states = encoder_outputs.last_hidden_state\n",
        "        encoder_hidden_states = self.longformer_projection(encoder_hidden_states)  # Appliquer la projection\n",
        "        decoder_outputs = self.bart(input_ids=decoder_input_ids, labels=labels, encoder_outputs=encoder_hidden_states)\n",
        "        return decoder_outputs\n",
        "\n",
        "# Charger Longformer et BART\n",
        "longformer_model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "bart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Charger les poids de notre modèle fine-tuné\n",
        "model = LongformerBart(longformer_model, bart)\n",
        "#model.load_state_dict(torch.load('/kaggle/input/longformer_bart_finetuned/pytorch/default/1/longformer_bart_finetuned/longformer_bart_finetuned.pth'))  # Remplacez par le bon chemin\n",
        "model.load_state_dict(torch.load('/kaggle/working/longformer_bart_finetuned/model_weights.pth'))  # Remplacez par le bon chemin et la ligne du dessus pour utiliser le modèle déjà réentrainé\n",
        "\n",
        "# Charger la configuration\n",
        "# Notez que vous devez avoir la configuration JSON pour le modèle personnalisé\n",
        "#config = LongformerConfig.from_json_file('/kaggle/input/longformer_bart_finetuned/pytorch/default/1/longformer_bart_finetuned/longformer_bart_finetuned_config.json')\n",
        "config = LongformerConfig.from_json_file('/kaggle/working/longformer_bart_finetuned/config.json') #idem : # Remplacez par le bon chemin et la ligne du dessus pour utiliser le modèle déjà réentrainé\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:13.614321Z",
          "iopub.execute_input": "2024-12-30T22:43:13.614628Z",
          "iopub.status.idle": "2024-12-30T22:43:19.933325Z",
          "shell.execute_reply.started": "2024-12-30T22:43:13.614603Z",
          "shell.execute_reply": "2024-12-30T22:43:19.932577Z"
        },
        "id": "HATXe296ubrX",
        "outputId": "48e27279-adc7-4b99-9813-0bfb6cb62236"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-21-88ae010882a4>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/working/longformer_bart_finetuned/model_weights.pth'))  # Remplacez par le bon chemin\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mise en forme des données \"OBS\" de test pour le test du modèle."
      ],
      "metadata": {
        "id": "uncbLOAvubrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Définir le chemin du dossier contenant les articles\n",
        "dossier_articles_test = \"/kaggle/input/m-2-maliash-resume-darticles-scientifiques/test/OBS_test/articles_OBS_test\"\n",
        "\n",
        "# Liste des fichiers dans le dossier\n",
        "fichiers_articles = [f for f in os.listdir(dossier_articles_test) if f.startswith(\"article-\")]\n",
        "\n",
        "# Dictionnaire pour stocker les articles par identifiant (avec contenu des fichiers)\n",
        "articles_test = {}\n",
        "\n",
        "# Remplir le dictionnaire avec les fichiers en fonction des identifiants\n",
        "for fichier in fichiers_articles:\n",
        "    # Extraire l'identifiant du fichier article\n",
        "    identifiant = fichier.split(\"-\")[1].split(\".\")[0]\n",
        "\n",
        "    # Lire le contenu du fichier\n",
        "    with open(os.path.join(dossier_articles_test, fichier), 'r') as f:\n",
        "        contenu_article = f.read()\n",
        "\n",
        "    # Ajouter l'article et son identifiant au dictionnaire\n",
        "    articles_test[identifiant] = {\"article\": contenu_article}\n",
        "\n",
        "# Convertir le dictionnaire en DataFrame\n",
        "df_articles_test = pd.DataFrame.from_dict(articles_test, orient='index')\n",
        "\n",
        "# Réinitialiser l'index pour que 'identifiant' devienne une colonne normale\n",
        "df_articles_test.reset_index(inplace=True)\n",
        "\n",
        "# Renommer les colonnes\n",
        "df_articles_test.columns = ['identifiant', 'article']\n",
        "\n",
        "# Vérifier le DataFrame\n",
        "print(df_articles_test.head())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:19.934075Z",
          "iopub.execute_input": "2024-12-30T22:43:19.934311Z",
          "iopub.status.idle": "2024-12-30T22:43:20.058591Z",
          "shell.execute_reply.started": "2024-12-30T22:43:19.934281Z",
          "shell.execute_reply": "2024-12-30T22:43:20.057649Z"
        },
        "id": "K8V5STEcubrZ",
        "outputId": "6ea12a5b-f0d6-452a-e7cb-e981d27b34da"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "  identifiant                                            article\n0    28278130  Cardiometabolic Risk Factors Among 1.3 Million...\n1    34555924  Prostate Cancer Screening and Incidence among ...\n2    35157313  The associated burden of mental health conditi...\n3    36906849  Implementing digital systems to facilitate gen...\n4    37226713  Patient-reported treatment response in chronic...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenisation des données et génération des résumés pour les articles de test de type \"OBS\""
      ],
      "metadata": {
        "id": "KBYJo8z7ubra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerTokenizer, BartTokenizer, BartForConditionalGeneration\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Initialiser les tokenizers Longformer et BART\n",
        "longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Charger un modèle BART pour la génération de résumé\n",
        "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "model = model\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenisation des articles et des résumés avec Longformer et BART respectivement.\n",
        "    \"\"\"\n",
        "    # Si 'examples' est une chaîne de texte, placez-la sous une clé dans un dictionnaire\n",
        "    if isinstance(examples, str):\n",
        "        examples = {\"article\": examples}\n",
        "\n",
        "    # Tokenisation de l'article avec Longformer\n",
        "    model_inputs = longformer_tokenizer(\n",
        "        examples[\"article\"],\n",
        "        max_length=1024,  # Longformer est capable de gérer de longs textes - mais kaggle ne supporte pas plus des 1024 tokens de long...\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Assurer le padding\n",
        "        return_tensors=\"pt\"  # Retourner des tensors PyTorch\n",
        "    )\n",
        "\n",
        "    # Tokenisation des résumés avec BART\n",
        "    labels = bart_tokenizer(\n",
        "        examples[\"abstract\"],  # Assume que \"abstract\" est la cible à tokenizer\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Assurer le padding\n",
        "        return_tensors=\"pt\"  # Retourner des tensors PyTorch\n",
        "    )\n",
        "\n",
        "    # Retourne les entrées et labels sous forme de dictionnaire\n",
        "    return {**model_inputs, \"labels\": labels[\"input_ids\"]}\n",
        "\n",
        "\n",
        "def generer_resume(article, model, tokenizer, max_length=150):\n",
        "    \"\"\"\n",
        "    Fonction pour générer un résumé d'un article en utilisant notre modèle Longformer-BART.\n",
        "    \"\"\"\n",
        "    # Tokenisation de l'article\n",
        "    inputs = tokenizer(article, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024)\n",
        "\n",
        "    # Si le modèle est en mode CPU, déplacer les entrées et le modèle sur le bon périphérique\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Obtenir les sorties du modèle\n",
        "    with torch.no_grad():\n",
        "        # Appeler la méthode forward du modèle en utilisant les bons paramètres\n",
        "        outputs = model(input_ids=inputs['input_ids'],\n",
        "                        attention_mask=inputs['attention_mask'],  # Remarque: utilisez 'attention_mask' ici\n",
        "                        decoder_input_ids=inputs['input_ids'],  # Utiliser les input_ids comme entrée pour le décodeur\n",
        "                        labels=None)\n",
        "\n",
        "    # Décoder le résumé depuis la sortie du modèle\n",
        "    # Utilisation de la méthode de génération du modèle BART sur les sorties de Longformer\n",
        "    summary_ids = model.bart.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_length,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Décoder les IDs générés pour obtenir le résumé\n",
        "    resume = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return resume\n",
        "\n",
        "def traiter_ensemble_test(dataset_RCT, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Fonction qui traite l'ensemble du dataset_RCT et génère des résumés pour chaque article.\n",
        "    \"\"\"\n",
        "    # Convertir le dataset en DataFrame si ce n'est pas déjà fait\n",
        "    df = pd.DataFrame(dataset_RCT)\n",
        "\n",
        "    # Créer une nouvelle colonne pour les résumés générés\n",
        "    df['résumé'] = df['article'].apply(lambda x: generer_resume(x, model, tokenizer))\n",
        "\n",
        "    # Afficher le résultat ou sauvegarder les résultats dans un fichier\n",
        "    return df[['identifiant', 'article', 'résumé']]\n",
        "\n",
        "\n",
        "# Traiter l'ensemble de test et générer les résumés\n",
        "resultats_obs = traiter_ensemble_test(df_articles_test, model, bart_tokenizer)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(resultats_obs)\n",
        "\n",
        "# Supprimer la colonne 'article' et renommer les colonnes dans 'resultats' (pour mise au bon format pour la compétition)\n",
        "resultats_obs = resultats_obs.drop(columns=['article'])  # Supprimer la colonne 'article'\n",
        "resultats_obs = resultats_obs.rename(columns={'identifiant': 'id', 'résumé': 'abstract'})  # Renommer les colonnes\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:20.059462Z",
          "iopub.execute_input": "2024-12-30T22:43:20.059705Z",
          "iopub.status.idle": "2024-12-30T22:43:49.736865Z",
          "shell.execute_reply.started": "2024-12-30T22:43:20.059685Z",
          "shell.execute_reply": "2024-12-30T22:43:49.735907Z"
        },
        "id": "tHZlxtWiubrb",
        "outputId": "bd412737-02cc-4858-cc77-9af31ed891cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   identifiant                                            article  \\\n0     28278130  Cardiometabolic Risk Factors Among 1.3 Million...   \n1     34555924  Prostate Cancer Screening and Incidence among ...   \n2     35157313  The associated burden of mental health conditi...   \n3     36906849  Implementing digital systems to facilitate gen...   \n4     37226713  Patient-reported treatment response in chronic...   \n5     37450671  Prevalence of Immunomodulator Use as Combinati...   \n6     37578507  Serum levels of endocannabinoids and related l...   \n7     37580243  Impact of antimicrobial stewardship in organis...   \n8     37586661  Effectiveness of intravenous immunoglobulin th...   \n9     37698611  Virological evidence of the impact of non-phar...   \n10    37870070  Clinical diagnosis of SARS-CoV-2 infection: An...   \n11    37924841  Association of patient clinical and gut microb...   \n12    38030736  Effects of maternal type 1 diabetes and confou...   \n13    38180993  Serum lactate and mean arterial pressure thres...   \n14    38289867  Electrical storm treatment by percutaneous ste...   \n15    38294526  Clinical practice and effect of carbon dioxide...   \n16    38296595  No detrimental association between antibiotic ...   \n17    38350309  Cumulative oxytocin dose in spontaneous labour...   \n18    38536065  Travel Distance Between Participants in US Tel...   \n19    38585623  Anaesthesiologic Considerations for Intraopera...   \n20    38622608  Feasibility and acceptability of remotely moni...   \n21    38627831  Goodbye Hartmann trial: a prospective, interna...   \n22    38649906  Raspberry leaf (Rubus idaeus) use in pregnancy...   \n23    38655251  Early dynamic changes to monocytes following m...   \n24    38664763  Comparing outcomes in patients with exsanguina...   \n\n                                               résumé  \n0   Cardiometabolic Risk Factors Among 1.3 Million...  \n1   Prostate Cancer Screening and Incidence among ...  \n2   The associated burden of mental health conditi...  \n3   Implementing digital systems to facilitate gen...  \n4   Chronic graft-versus-host disease (GvHD) is th...  \n5   Prevalence of Immunomodulator Use as Combinati...  \n6   Serum levels of endocannabinoids and related l...  \n7   Impact of antimicrobial stewardship in organis...  \n8   Effectiveness of intravenous immunoglobulin th...  \n9   Virological evidence of the impact of non-phar...  \n10  Clinical diagnosis of SARS-CoV-2 infection: An...  \n11  Association of patient clinical and gut microb...  \n12  Effects of maternal type 1 diabetes and confou...  \n13  Serum lactate and mean arterial pressure thres...  \n14  Electrical storm treatment by percutaneous ste...  \n15  Clinical practice and effect of carbon dioxide...  \n16  No detrimental association between antibiotic ...  \n17  Cumulative oxytocin dose in spontaneous labour...  \n18  Travel Distance Between Participants in US Tel...  \n19  Intraoperative extracorporeal membrane oxygena...  \n20  Feasibility and acceptability of remotely moni...  \n21  Goodbye Hartmann trial: a prospective, interna...  \n22  Raspberry leaf is one of the most common herbs...  \n23  Early dynamic changes to monocytes following m...  \n24  Comparing outcomes in patients with exsanguina...  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chargement de notre modèle fine-tuné sur les données \"RCT\" et constitué à partir des deux modèles bart et longformer, pour pouvoir l'utiliser pour l'ensemble de test et soumettre nos résumés pour la compétition"
      ],
      "metadata": {
        "id": "nvVdA05Vubrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Charger le modèle fine tuné afin de l'utiliser\n",
        "import torch\n",
        "from transformers import LongformerModel, BartForConditionalGeneration, LongformerConfig\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Définir la classe LongformerBart\n",
        "class LongformerBart(nn.Module):\n",
        "    def __init__(self, longformer_model, bart_model):\n",
        "        super(LongformerBart, self).__init__()\n",
        "        self.longformer = longformer_model\n",
        "        self.bart = bart_model\n",
        "        self.longformer_projection = nn.Linear(768, 1024)  # Projeter de 768 à 1024\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_input_ids=None, labels=None):\n",
        "        encoder_outputs = self.longformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        encoder_hidden_states = encoder_outputs.last_hidden_state\n",
        "        encoder_hidden_states = self.longformer_projection(encoder_hidden_states)  # Appliquer la projection\n",
        "        decoder_outputs = self.bart(input_ids=decoder_input_ids, labels=labels, encoder_outputs=encoder_hidden_states)\n",
        "        return decoder_outputs\n",
        "\n",
        "# Charger Longformer et BART\n",
        "longformer_model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "bart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Charger les poids de notre modèle fine-tuné\n",
        "model = LongformerBart(longformer_model, bart)\n",
        "model.load_state_dict(torch.load('/kaggle/input/longformer_bart_fine_tuned_rct/pytorch/default/1/model_weights.pth'))\n",
        "#model.load_state_dict(torch.load('/kaggle/working/longformer_bart_finetuned_rct/model_weigths.pth')) # Remplacez par le bon chemin et cette ligne si vous réentrainez le modèle\n",
        "\n",
        "\n",
        "\n",
        "# Charger la configuration\n",
        "# Notez que vous devez avoir la configuration JSON pour le modèle personnalisé\n",
        "config = LongformerConfig.from_json_file('/kaggle/input/longformer_bart_fine_tuned_rct/pytorch/default/1/config.json')\n",
        "#config = LongformerConfig.from_json_file('/kaggle/working/longformer_bart_finetuned_rct/config.json') #idem : Remplacez par le bon chemin et cette ligne si vous réentrainez le modèle\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:43:49.737673Z",
          "iopub.execute_input": "2024-12-30T22:43:49.737888Z",
          "iopub.status.idle": "2024-12-30T22:44:08.028123Z",
          "shell.execute_reply.started": "2024-12-30T22:43:49.737869Z",
          "shell.execute_reply": "2024-12-30T22:44:08.027216Z"
        },
        "id": "C5dkjxe7ubrd",
        "outputId": "fe1e63e3-b7e9-454f-8d1c-8e937f1a33b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-24-c5822b5fd9d3>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('/kaggle/input/longformer_bart_fine_tuned_rct/pytorch/default/1/model_weights.pth'))\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Mise en forme des données à tester\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Définir le chemin du dossier contenant les articles\n",
        "dossier_articles_test = \"/kaggle/input/m-2-maliash-resume-darticles-scientifiques/test/RCT_test/articles_RCT_test\"\n",
        "\n",
        "# Liste des fichiers dans le dossier\n",
        "fichiers_articles = [f for f in os.listdir(dossier_articles_test) if f.startswith(\"article-\")]\n",
        "\n",
        "# Dictionnaire pour stocker les articles par identifiant (avec contenu des fichiers)\n",
        "articles_test = {}\n",
        "\n",
        "# Remplir le dictionnaire avec les fichiers en fonction des identifiants\n",
        "for fichier in fichiers_articles:\n",
        "    # Extraire l'identifiant du fichier article\n",
        "    identifiant = fichier.split(\"-\")[1].split(\".\")[0]\n",
        "\n",
        "    # Lire le contenu du fichier\n",
        "    with open(os.path.join(dossier_articles_test, fichier), 'r') as f:\n",
        "        contenu_article = f.read()\n",
        "\n",
        "    # Ajouter l'article et son identifiant au dictionnaire\n",
        "    articles_test[identifiant] = {\"article\": contenu_article}\n",
        "\n",
        "# Convertir le dictionnaire en DataFrame\n",
        "df_articles_test = pd.DataFrame.from_dict(articles_test, orient='index')\n",
        "\n",
        "# Réinitialiser l'index pour que 'identifiant' devienne une colonne normale\n",
        "df_articles_test.reset_index(inplace=True)\n",
        "\n",
        "# Renommer les colonnes\n",
        "df_articles_test.columns = ['identifiant', 'article']\n",
        "# Vérifier le DataFrame\n",
        "print(df_articles_test.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:44:08.029013Z",
          "iopub.execute_input": "2024-12-30T22:44:08.029245Z",
          "iopub.status.idle": "2024-12-30T22:44:08.141115Z",
          "shell.execute_reply.started": "2024-12-30T22:44:08.029224Z",
          "shell.execute_reply": "2024-12-30T22:44:08.140223Z"
        },
        "id": "9z6rlpcCubre",
        "outputId": "c4484c38-433c-4bf3-8600-6708c392d2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "  identifiant                                            article\n0    26811968  Randomized Controlled Trial of Hospital-Based ...\n1    34737472  Behavioural intervention for adolescent uptake...\n2    34844893  Prediction of clinical response to corticoster...\n3    34969647  Feasibility and efficacy of a multidisciplinar...\n4    35532871  Iron homeostasis in heart transplant recipient...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenisation des données et génération des résumés pour les articles de test de type \"RCT\""
      ],
      "metadata": {
        "id": "gD7watHRubrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerTokenizer, BartTokenizer, BartForConditionalGeneration\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Initialiser les tokenizers Longformer et BART\n",
        "longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Charger un modèle BART pour la génération de résumé\n",
        "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "model = model\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    Tokenisation des articles et des résumés avec Longformer et BART respectivement.\n",
        "    \"\"\"\n",
        "    # Si 'examples' est une chaîne de texte, placez-la sous une clé dans un dictionnaire\n",
        "    if isinstance(examples, str):\n",
        "        examples = {\"article\": examples}\n",
        "\n",
        "    # Tokenisation de l'article avec Longformer\n",
        "    model_inputs = longformer_tokenizer(\n",
        "        examples[\"article\"],\n",
        "        max_length=1024,  # Longformer est capable de gérer de longs textes - mais kaggle ne supporte pas plus des 1024 tokens de long...\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Assurer le padding\n",
        "        return_tensors=\"pt\"  # Retourner des tensors PyTorch\n",
        "    )\n",
        "\n",
        "    # Tokenisation des résumés avec BART\n",
        "    labels = bart_tokenizer(\n",
        "        examples[\"abstract\"],  # Assume que \"abstract\" est la cible à tokenizer\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",  # Assurer le padding\n",
        "        return_tensors=\"pt\"  # Retourner des tensors PyTorch\n",
        "    )\n",
        "\n",
        "    # Retourne les entrées et labels sous forme de dictionnaire\n",
        "    return {**model_inputs, \"labels\": labels[\"input_ids\"]}\n",
        "\n",
        "\n",
        "def generer_resume(article, model, tokenizer, max_length=150):\n",
        "    \"\"\"\n",
        "    Fonction pour générer un résumé d'un article en utilisant notre modèle Longformer-BART.\n",
        "    \"\"\"\n",
        "    # Tokenisation de l'article\n",
        "    inputs = tokenizer(article, return_tensors=\"pt\", truncation=True, padding=True, max_length=1024)\n",
        "\n",
        "    # Si le modèle est en mode CPU, déplacer les entrées et le modèle sur le bon périphérique\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Obtenir les sorties du modèle\n",
        "    with torch.no_grad():\n",
        "        # Appeler la méthode forward du modèle en utilisant les bons paramètres\n",
        "        outputs = model(input_ids=inputs['input_ids'],\n",
        "                        attention_mask=inputs['attention_mask'],  # Remarque: utilisez 'attention_mask' ici\n",
        "                        decoder_input_ids=inputs['input_ids'],  # Utiliser les input_ids comme entrée pour le décodeur\n",
        "                        labels=None)\n",
        "\n",
        "    # Décoder le résumé depuis la sortie du modèle\n",
        "    # Utilisation de la méthode de génération du modèle BART sur les sorties de Longformer\n",
        "    summary_ids = model.bart.generate(\n",
        "        inputs['input_ids'],\n",
        "        max_length=max_length,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Décoder les IDs générés pour obtenir le résumé\n",
        "    resume = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return resume\n",
        "\n",
        "def traiter_ensemble_test(dataset_RCT, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Fonction qui traite l'ensemble du dataset_RCT et génère des résumés pour chaque article.\n",
        "    \"\"\"\n",
        "    # Convertir le dataset en DataFrame si ce n'est pas déjà fait\n",
        "    df = pd.DataFrame(dataset_RCT)\n",
        "\n",
        "    # Créer une nouvelle colonne pour les résumés générés\n",
        "    df['résumé'] = df['article'].apply(lambda x: generer_resume(x, model, tokenizer))\n",
        "\n",
        "    # Afficher le résultat ou sauvegarder les résultats dans un fichier\n",
        "    return df[['identifiant', 'article', 'résumé']]\n",
        "\n",
        "\n",
        "# Traiter l'ensemble de test et générer les résumés\n",
        "resultats_rct = traiter_ensemble_test(df_articles_test, model, bart_tokenizer)\n",
        "\n",
        "# Afficher les résultats\n",
        "print(resultats_rct)\n",
        "\n",
        "# Supprimer la colonne 'article' et renommer les colonnes dans 'resultats' (pour mise au bon format pour la compétition)\n",
        "resultats_rct = resultats_rct.drop(columns=['article'])  # Supprimer la colonne 'article'\n",
        "resultats_rct = resultats_rct.rename(columns={'identifiant': 'id', 'résumé': 'abstract'})  # Renommer les colonnes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:44:08.142043Z",
          "iopub.execute_input": "2024-12-30T22:44:08.142326Z",
          "iopub.status.idle": "2024-12-30T22:44:38.602767Z",
          "shell.execute_reply.started": "2024-12-30T22:44:08.142269Z",
          "shell.execute_reply": "2024-12-30T22:44:38.601886Z"
        },
        "id": "Az6flzoXubrg",
        "outputId": "30d5bebd-4bd1-4152-bbe0-10e3256d447e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   identifiant                                            article  \\\n0     26811968  Randomized Controlled Trial of Hospital-Based ...   \n1     34737472  Behavioural intervention for adolescent uptake...   \n2     34844893  Prediction of clinical response to corticoster...   \n3     34969647  Feasibility and efficacy of a multidisciplinar...   \n4     35532871  Iron homeostasis in heart transplant recipient...   \n5     35638317  The effect of duloxetine on mechanistic pain p...   \n6     36479935  Clinical Predictors of Adherence to Exercise T...   \n7     36621009  Supporting return to work after psychiatric ho...   \n8     37972955  LIGHTSITE III: 13-Month Efficacy and Safety Ev...   \n9     37991188  Evolution in Laparoscopic Gastrectomy From a R...   \n10    38052803  Long-term outcome of children with acute promy...   \n11    38060092  Efficacy and Safety of the Travoprost Intraocu...   \n12    38117526  Efficacy and Safety of PF-07038124 in Patients...   \n13    38184526  Prognostic significance of surgery and radioth...   \n14    38189649  Determinants of Subjective Mental and Function...   \n15    38197254  Daily skin-to-skin contact alters microbiota d...   \n16    38218840  The effectiveness of an m-Health intervention ...   \n17    38315470  Alirocumab in Pediatric Patients With Heterozy...   \n18    38417090  Effectiveness of Seizure Dogs for People With ...   \n19    38437855  Active vitamin D treatment in the prevention o...   \n20    38446126  Intravenous iron for heart failure, iron defic...   \n21    38531621  Guselkumab provides durable improvement across...   \n22    38591920  Multi-strain probiotics during pregnancy in wo...   \n23    38609994  The effects of telehealth-delivered mindfulnes...   \n24    38668732  A randomized controlled trial of a postdischar...   \n\n                                               résumé  \n0   Randomized Controlled Trial of Hospital-Based ...  \n1   Behavioural intervention for adolescent uptake...  \n2   Prediction of clinical response to corticoster...  \n3   Feasibility and efficacy of a multidisciplinar...  \n4   Iron homeostasis in heart transplant recipient...  \n5   abstract.com. The abstract is a comprehensive ...  \n6   Heart Failure: A Controlled Trial Investigatin...  \n7   Supporting return to work after psychiatric ho...  \n8   LIGHTSITE III: 13-month Efficacy and Safety Ev...  \n9   Evolution in Laparoscopic Gastrectomy From a R...  \n10  Arsenic-based therapy substantially improves t...  \n11  Travoprost Intraocular Implant Reduces Topical...  \n12  Atopic dermatitis and plaque psoriasis are chr...  \n13  Prognostic significance of surgery and radioth...  \n14  ICU survivors frequently suffer from impairmen...  \n15  Daily skin-to-skin contact alters microbiota d...  \n16  The effectiveness of an m-Health intervention ...  \n17  Alirocumab in Pediatric Patients With Heterozy...  \n18  Effectiveness of Seizure Dogs for People With ...  \n19  Active vitamin D treatment in the prevention o...  \n20  Intravenous iron increases haemoglobin, improv...  \n21  Guselkumab provides durable improvement across...  \n22  Multi-strain probiotics during pregnancy in wo...  \n23  The effects of telehealth-delivered mindfulnes...  \n24  A randomized controlled trial of a postdischar...  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fusion de nos deux fichiers de résumés générés (resultats_obs et resultats_rct) en un seul fichier submission, puis conversion en csv pour soumission à la compétition (permet d'avoir le score rouge)."
      ],
      "metadata": {
        "id": "Cmq30KgHubri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concaténer les deux DataFrames\n",
        "resultats = pd.concat([resultats_obs, resultats_rct], ignore_index=True)\n",
        "\n",
        "# Sauvegarder le DataFrame concaténé dans un fichier CSV, si nécessaire\n",
        "resultats.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Afficher le DataFrame concaténé\n",
        "print(resultats)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-30T22:44:38.605905Z",
          "iopub.execute_input": "2024-12-30T22:44:38.606133Z",
          "iopub.status.idle": "2024-12-30T22:44:38.618351Z",
          "shell.execute_reply.started": "2024-12-30T22:44:38.606113Z",
          "shell.execute_reply": "2024-12-30T22:44:38.617625Z"
        },
        "id": "pcXG6WY_ubrj",
        "outputId": "3e256ebf-7e9e-4908-fb6f-3f32eed4e8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "          id                                           abstract\n0   28278130  Cardiometabolic Risk Factors Among 1.3 Million...\n1   34555924  Prostate Cancer Screening and Incidence among ...\n2   35157313  The associated burden of mental health conditi...\n3   36906849  Implementing digital systems to facilitate gen...\n4   37226713  Chronic graft-versus-host disease (GvHD) is th...\n5   37450671  Prevalence of Immunomodulator Use as Combinati...\n6   37578507  Serum levels of endocannabinoids and related l...\n7   37580243  Impact of antimicrobial stewardship in organis...\n8   37586661  Effectiveness of intravenous immunoglobulin th...\n9   37698611  Virological evidence of the impact of non-phar...\n10  37870070  Clinical diagnosis of SARS-CoV-2 infection: An...\n11  37924841  Association of patient clinical and gut microb...\n12  38030736  Effects of maternal type 1 diabetes and confou...\n13  38180993  Serum lactate and mean arterial pressure thres...\n14  38289867  Electrical storm treatment by percutaneous ste...\n15  38294526  Clinical practice and effect of carbon dioxide...\n16  38296595  No detrimental association between antibiotic ...\n17  38350309  Cumulative oxytocin dose in spontaneous labour...\n18  38536065  Travel Distance Between Participants in US Tel...\n19  38585623  Intraoperative extracorporeal membrane oxygena...\n20  38622608  Feasibility and acceptability of remotely moni...\n21  38627831  Goodbye Hartmann trial: a prospective, interna...\n22  38649906  Raspberry leaf is one of the most common herbs...\n23  38655251  Early dynamic changes to monocytes following m...\n24  38664763  Comparing outcomes in patients with exsanguina...\n25  26811968  Randomized Controlled Trial of Hospital-Based ...\n26  34737472  Behavioural intervention for adolescent uptake...\n27  34844893  Prediction of clinical response to corticoster...\n28  34969647  Feasibility and efficacy of a multidisciplinar...\n29  35532871  Iron homeostasis in heart transplant recipient...\n30  35638317  abstract.com. The abstract is a comprehensive ...\n31  36479935  Heart Failure: A Controlled Trial Investigatin...\n32  36621009  Supporting return to work after psychiatric ho...\n33  37972955  LIGHTSITE III: 13-month Efficacy and Safety Ev...\n34  37991188  Evolution in Laparoscopic Gastrectomy From a R...\n35  38052803  Arsenic-based therapy substantially improves t...\n36  38060092  Travoprost Intraocular Implant Reduces Topical...\n37  38117526  Atopic dermatitis and plaque psoriasis are chr...\n38  38184526  Prognostic significance of surgery and radioth...\n39  38189649  ICU survivors frequently suffer from impairmen...\n40  38197254  Daily skin-to-skin contact alters microbiota d...\n41  38218840  The effectiveness of an m-Health intervention ...\n42  38315470  Alirocumab in Pediatric Patients With Heterozy...\n43  38417090  Effectiveness of Seizure Dogs for People With ...\n44  38437855  Active vitamin D treatment in the prevention o...\n45  38446126  Intravenous iron increases haemoglobin, improv...\n46  38531621  Guselkumab provides durable improvement across...\n47  38591920  Multi-strain probiotics during pregnancy in wo...\n48  38609994  The effects of telehealth-delivered mindfulnes...\n49  38668732  A randomized controlled trial of a postdischar...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}